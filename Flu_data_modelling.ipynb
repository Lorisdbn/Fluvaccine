{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "826ded54-1fe2-45ca-b8e2-ec393f2f5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Filepath\n",
    "folder_path = r\"C:\\Users\\loris\\Desktop\\Flu_Prediction_Project\"\n",
    "file_path = f\"{folder_path}/training_set_processed.csv\"\n",
    "\n",
    "# Charging the files\n",
    "df = pd.read_csv(file_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c93bd37-bda5-4305-a5d6-773a29f70cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>...</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.681849</td>\n",
       "      <td>-2.044279</td>\n",
       "      <td>-0.226293</td>\n",
       "      <td>-1.634957</td>\n",
       "      <td>-0.272097</td>\n",
       "      <td>-2.177944</td>\n",
       "      <td>-0.74589</td>\n",
       "      <td>1.404892</td>\n",
       "      <td>0.687870</td>\n",
       "      <td>-0.580793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.518373</td>\n",
       "      <td>1.197027</td>\n",
       "      <td>-0.226293</td>\n",
       "      <td>0.611637</td>\n",
       "      <td>-0.272097</td>\n",
       "      <td>0.459149</td>\n",
       "      <td>-0.74589</td>\n",
       "      <td>1.404892</td>\n",
       "      <td>0.687870</td>\n",
       "      <td>-0.580793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.681849</td>\n",
       "      <td>-0.423626</td>\n",
       "      <td>-0.226293</td>\n",
       "      <td>0.611637</td>\n",
       "      <td>-0.272097</td>\n",
       "      <td>-2.177944</td>\n",
       "      <td>-0.74589</td>\n",
       "      <td>-0.711798</td>\n",
       "      <td>-1.453764</td>\n",
       "      <td>2.608196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.681849</td>\n",
       "      <td>-0.423626</td>\n",
       "      <td>-0.226293</td>\n",
       "      <td>0.611637</td>\n",
       "      <td>-0.272097</td>\n",
       "      <td>0.459149</td>\n",
       "      <td>1.34068</td>\n",
       "      <td>-0.711798</td>\n",
       "      <td>-1.453764</td>\n",
       "      <td>-0.580793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.418262</td>\n",
       "      <td>-0.423626</td>\n",
       "      <td>-0.226293</td>\n",
       "      <td>0.611637</td>\n",
       "      <td>-0.272097</td>\n",
       "      <td>0.459149</td>\n",
       "      <td>1.34068</td>\n",
       "      <td>-0.711798</td>\n",
       "      <td>0.687870</td>\n",
       "      <td>-0.580793</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "0     -0.681849       -2.044279                  -0.226293   \n",
       "1      1.518373        1.197027                  -0.226293   \n",
       "2     -0.681849       -0.423626                  -0.226293   \n",
       "3     -0.681849       -0.423626                  -0.226293   \n",
       "4      0.418262       -0.423626                  -0.226293   \n",
       "\n",
       "   behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "0             -1.634957             -0.272097              -2.177944   \n",
       "1              0.611637             -0.272097               0.459149   \n",
       "2              0.611637             -0.272097              -2.177944   \n",
       "3              0.611637             -0.272097               0.459149   \n",
       "4              0.611637             -0.272097               0.459149   \n",
       "\n",
       "   behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "0                     -0.74589                 1.404892   \n",
       "1                     -0.74589                 1.404892   \n",
       "2                     -0.74589                -0.711798   \n",
       "3                      1.34068                -0.711798   \n",
       "4                      1.34068                -0.711798   \n",
       "\n",
       "   behavioral_touch_face  doctor_recc_h1n1  ...  income_poverty  \\\n",
       "0               0.687870         -0.580793  ...             0.0   \n",
       "1               0.687870         -0.580793  ...             0.0   \n",
       "2              -1.453764          2.608196  ...             1.0   \n",
       "3              -1.453764         -0.580793  ...             0.0   \n",
       "4               0.687870         -0.580793  ...             1.0   \n",
       "\n",
       "   marital_status  rent_or_own  employment_status  hhs_geo_region  census_msa  \\\n",
       "0             0.0          0.0                0.0             0.0         0.0   \n",
       "1             0.0          1.0                1.0             1.0         1.0   \n",
       "2             0.0          0.0                1.0             2.0         1.0   \n",
       "3             0.0          1.0                0.0             3.0         2.0   \n",
       "4             1.0          0.0                1.0             2.0         1.0   \n",
       "\n",
       "   employment_industry  employment_occupation  h1n1_vaccine  seasonal_vaccine  \n",
       "0                 -1.0                   -1.0           0.0               0.0  \n",
       "1                  0.0                    0.0           0.0               1.0  \n",
       "2                  1.0                    1.0           0.0               0.0  \n",
       "3                 -1.0                   -1.0           0.0               1.0  \n",
       "4                  2.0                    2.0           0.0               0.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94fc96-bf34-4709-8f47-a3b3995110b6",
   "metadata": {},
   "source": [
    "# Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eefbd934-8540-4888-8b77-6cc26ba39f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance pour H1N1 Vaccine:\n",
      "Accuracy: 0.83\n",
      "Confusion Matrix:\n",
      "[[3997  215]\n",
      " [ 684  446]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.95      0.90      4212\n",
      "         1.0       0.67      0.39      0.50      1130\n",
      "\n",
      "    accuracy                           0.83      5342\n",
      "   macro avg       0.76      0.67      0.70      5342\n",
      "weighted avg       0.82      0.83      0.81      5342\n",
      "\n",
      "\n",
      "Performance pour Seasonal Vaccine:\n",
      "Accuracy: 0.76\n",
      "Confusion Matrix:\n",
      "[[2303  588]\n",
      " [ 687 1764]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.80      0.78      2891\n",
      "         1.0       0.75      0.72      0.73      2451\n",
      "\n",
      "    accuracy                           0.76      5342\n",
      "   macro avg       0.76      0.76      0.76      5342\n",
      "weighted avg       0.76      0.76      0.76      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Split the data (features/target)\n",
    "X = df.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])\n",
    "y_h1n1 = df['h1n1_vaccine']\n",
    "y_seasonal = df['seasonal_vaccine']\n",
    "\n",
    "# Split the data (train and test set)\n",
    "X_train_h1n1, X_test_h1n1, y_train_h1n1, y_test_h1n1 = train_test_split(X, y_h1n1, test_size=0.2, random_state=42)\n",
    "X_train_seasonal, X_test_seasonal, y_train_seasonal, y_test_seasonal = train_test_split(X, y_seasonal, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the logistic regression model\n",
    "model_h1n1 = LogisticRegression(max_iter=1000)\n",
    "model_seasonal = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "model_h1n1.fit(X_train_h1n1, y_train_h1n1)\n",
    "model_seasonal.fit(X_train_seasonal, y_train_seasonal)\n",
    "\n",
    "# Predict \n",
    "y_pred_h1n1 = model_h1n1.predict(X_test_h1n1)\n",
    "y_pred_seasonal = model_seasonal.predict(X_test_seasonal)\n",
    "\n",
    "# Performance assessment\n",
    "print(\"Performance pour H1N1 Vaccine:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_h1n1, y_pred_h1n1):.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_h1n1, y_pred_h1n1))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_h1n1, y_pred_h1n1))\n",
    "\n",
    "print(\"\\nPerformance pour Seasonal Vaccine:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_seasonal, y_pred_seasonal):.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_seasonal, y_pred_seasonal))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_seasonal, y_pred_seasonal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc979550-f23d-4b49-87ce-76e5bc1a5d66",
   "metadata": {},
   "source": [
    "# Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ff4556b-4e12-4fc6-9694-4a615337db3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for H1N1 Vaccine:\n",
      "Training Time: 5.36 seconds\n",
      "Prediction Time: 0.23 seconds\n",
      "Accuracy: 0.85\n",
      "Confusion Matrix:\n",
      "[[4061  151]\n",
      " [ 636  494]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.96      0.91      4212\n",
      "         1.0       0.77      0.44      0.56      1130\n",
      "\n",
      "    accuracy                           0.85      5342\n",
      "   macro avg       0.82      0.70      0.73      5342\n",
      "weighted avg       0.84      0.85      0.84      5342\n",
      "\n",
      "\n",
      "Performance for Seasonal Vaccine:\n",
      "Training Time: 5.70 seconds\n",
      "Prediction Time: 0.27 seconds\n",
      "Accuracy: 0.78\n",
      "Confusion Matrix:\n",
      "[[2356  535]\n",
      " [ 641 1810]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.81      0.80      2891\n",
      "         1.0       0.77      0.74      0.75      2451\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.78      0.78      0.78      5342\n",
      "weighted avg       0.78      0.78      0.78      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "# The target columns are 'h1n1_vaccine' and 'seasonal_vaccine'\n",
    "X = df.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])\n",
    "y_h1n1 = df['h1n1_vaccine']\n",
    "y_seasonal = df['seasonal_vaccine']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_h1n1, X_test_h1n1, y_train_h1n1, y_test_h1n1 = train_test_split(X, y_h1n1, test_size=0.2, random_state=42)\n",
    "X_train_seasonal, X_test_seasonal, y_train_seasonal, y_test_seasonal = train_test_split(X, y_seasonal, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Random Forest model\n",
    "model_h1n1 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_seasonal = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Measure the training time for H1N1 model\n",
    "start_time = time.time()\n",
    "model_h1n1.fit(X_train_h1n1, y_train_h1n1)\n",
    "training_time_h1n1 = time.time() - start_time\n",
    "\n",
    "# Measure the prediction time for H1N1 model\n",
    "start_time = time.time()\n",
    "y_pred_h1n1 = model_h1n1.predict(X_test_h1n1)\n",
    "prediction_time_h1n1 = time.time() - start_time\n",
    "\n",
    "# Measure the training time for Seasonal model\n",
    "start_time = time.time()\n",
    "model_seasonal.fit(X_train_seasonal, y_train_seasonal)\n",
    "training_time_seasonal = time.time() - start_time\n",
    "\n",
    "# Measure the prediction time for Seasonal model\n",
    "start_time = time.time()\n",
    "y_pred_seasonal = model_seasonal.predict(X_test_seasonal)\n",
    "prediction_time_seasonal = time.time() - start_time\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print(\"Performance for H1N1 Vaccine:\")\n",
    "print(f\"Training Time: {training_time_h1n1:.2f} seconds\")\n",
    "print(f\"Prediction Time: {prediction_time_h1n1:.2f} seconds\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_h1n1, y_pred_h1n1):.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_h1n1, y_pred_h1n1))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_h1n1, y_pred_h1n1))\n",
    "\n",
    "print(\"\\nPerformance for Seasonal Vaccine:\")\n",
    "print(f\"Training Time: {training_time_seasonal:.2f} seconds\")\n",
    "print(f\"Prediction Time: {prediction_time_seasonal:.2f} seconds\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_seasonal, y_pred_seasonal):.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_seasonal, y_pred_seasonal))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_seasonal, y_pred_seasonal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4552fe49-a082-4be1-9efd-d6486e1cc3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loris\\Documents\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for H1N1 Vaccine: {'class_weight': 'balanced_subsample', 'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loris\\Documents\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Seasonal Vaccine: {'class_weight': 'balanced_subsample', 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Définir les hyperparamètres à tester\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "# Créer un modèle Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Configurer GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                           cv=5, n_jobs=-1, verbose=2, scoring='f1')\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement pour H1N1 Vaccine\n",
    "grid_search.fit(X_train_h1n1, y_train_h1n1)\n",
    "\n",
    "# Meilleurs hyperparamètres pour H1N1 Vaccine\n",
    "best_params_h1n1 = grid_search.best_params_\n",
    "print(\"Best parameters for H1N1 Vaccine:\", best_params_h1n1)\n",
    "\n",
    "# Entraîner le modèle avec les meilleurs hyperparamètres pour Seasonal Vaccine\n",
    "grid_search.fit(X_train_seasonal, y_train_seasonal)\n",
    "\n",
    "# Meilleurs hyperparamètres pour Seasonal Vaccine\n",
    "best_params_seasonal = grid_search.best_params_\n",
    "print(\"Best parameters for Seasonal Vaccine:\", best_params_seasonal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc01f8c4-fdc9-4552-90c5-87a4c7f8c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Performance for H1N1 Vaccine:\n",
      "Training Time: 13.93 seconds\n",
      "Prediction Time: 0.60 seconds\n",
      "Accuracy: 0.84\n",
      "Confusion Matrix:\n",
      "[[3759  453]\n",
      " [ 417  713]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.89      0.90      4212\n",
      "         1.0       0.61      0.63      0.62      1130\n",
      "\n",
      "    accuracy                           0.84      5342\n",
      "   macro avg       0.76      0.76      0.76      5342\n",
      "weighted avg       0.84      0.84      0.84      5342\n",
      "\n",
      "\n",
      "Optimized Performance for Seasonal Vaccine:\n",
      "Training Time: 6.43 seconds\n",
      "Prediction Time: 0.28 seconds\n",
      "Accuracy: 0.79\n",
      "Confusion Matrix:\n",
      "[[2313  578]\n",
      " [ 567 1884]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.80      0.80      2891\n",
      "         1.0       0.77      0.77      0.77      2451\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.78      0.78      0.78      5342\n",
      "weighted avg       0.79      0.79      0.79      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Best hyperparameters for H1N1 Vaccine\n",
    "best_params_h1n1 = {\n",
    "    'class_weight': 'balanced_subsample',\n",
    "    'max_depth': 20,\n",
    "    'max_features': 'sqrt',  # Changed from 'auto' to 'sqrt'\n",
    "    'min_samples_leaf': 4,\n",
    "    'min_samples_split': 10,\n",
    "    'n_estimators': 300\n",
    "}\n",
    "\n",
    "# Best hyperparameters for Seasonal Vaccine\n",
    "best_params_seasonal = {\n",
    "    'class_weight': 'balanced_subsample',\n",
    "    'max_depth': None,\n",
    "    'max_features': 'sqrt',  # Changed from 'auto' to 'sqrt'\n",
    "    'min_samples_leaf': 4,\n",
    "    'min_samples_split': 10,\n",
    "    'n_estimators': 200\n",
    "}\n",
    "\n",
    "# Measure training time for the optimized model for H1N1 Vaccine\n",
    "start_time = time.time()\n",
    "rf_h1n1_optimized = RandomForestClassifier(**best_params_h1n1, random_state=42)\n",
    "rf_h1n1_optimized.fit(X_train_h1n1, y_train_h1n1)\n",
    "training_time_h1n1 = time.time() - start_time\n",
    "\n",
    "# Measure prediction time for the optimized model for H1N1 Vaccine\n",
    "start_time = time.time()\n",
    "y_pred_h1n1_optimized = rf_h1n1_optimized.predict(X_test_h1n1)\n",
    "prediction_time_h1n1 = time.time() - start_time\n",
    "\n",
    "# Measure training time for the optimized model for Seasonal Vaccine\n",
    "start_time = time.time()\n",
    "rf_seasonal_optimized = RandomForestClassifier(**best_params_seasonal, random_state=42)\n",
    "rf_seasonal_optimized.fit(X_train_seasonal, y_train_seasonal)\n",
    "training_time_seasonal = time.time() - start_time\n",
    "\n",
    "# Measure prediction time for the optimized model for Seasonal Vaccine\n",
    "start_time = time.time()\n",
    "y_pred_seasonal_optimized = rf_seasonal_optimized.predict(X_test_seasonal)\n",
    "prediction_time_seasonal = time.time() - start_time\n",
    "\n",
    "# Evaluate the performance of the optimized models\n",
    "print(\"Optimized Performance for H1N1 Vaccine:\")\n",
    "print(f\"Training Time: {training_time_h1n1:.2f} seconds\")\n",
    "print(f\"Prediction Time: {prediction_time_h1n1:.2f} seconds\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_h1n1, y_pred_h1n1_optimized):.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_h1n1, y_pred_h1n1_optimized))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_h1n1, y_pred_h1n1_optimized))\n",
    "\n",
    "print(\"\\nOptimized Performance for Seasonal Vaccine:\")\n",
    "print(f\"Training Time: {training_time_seasonal:.2f} seconds\")\n",
    "print(f\"Prediction Time: {prediction_time_seasonal:.2f} seconds\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_seasonal, y_pred_seasonal_optimized):.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_seasonal, y_pred_seasonal_optimized))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_seasonal, y_pred_seasonal_optimized))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27744289-81ff-4486-891f-00d5301726c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results for H1N1 Vaccine Model:\n",
      "Accuracy Scores per Fold: [0.83243623 0.84811608 0.83664872 0.84530775 0.84179733]\n",
      "Mean Accuracy: 0.8409\n",
      "Standard Deviation: 0.0057\n",
      "\n",
      "Cross-Validation Results for Seasonal Vaccine Model:\n",
      "Accuracy Scores per Fold: [0.79499181 0.77978001 0.77112099 0.77767377 0.77533349]\n",
      "Mean Accuracy: 0.7798\n",
      "Standard Deviation: 0.0081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Supposons que X et y soient vos features et votre target\n",
    "# X = df_processed.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])\n",
    "# y_h1n1 = df_processed['h1n1_vaccine']\n",
    "# y_seasonal = df_processed['seasonal_vaccine']\n",
    "\n",
    "# Créer un modèle Random Forest avec les meilleurs hyperparamètres (vous pouvez ajuster ces paramètres)\n",
    "model_h1n1 = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=20,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=4,\n",
    "    min_samples_split=10,\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Définir le K-Fold Cross Validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Effectuer la validation croisée pour le modèle H1N1\n",
    "cv_results_h1n1 = cross_val_score(model_h1n1, X_train_h1n1, y_train_h1n1, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Cross-Validation Results for H1N1 Vaccine Model:\")\n",
    "print(f\"Accuracy Scores per Fold: {cv_results_h1n1}\")\n",
    "print(f\"Mean Accuracy: {np.mean(cv_results_h1n1):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(cv_results_h1n1):.4f}\")\n",
    "\n",
    "# Répéter pour le modèle Seasonal Vaccine\n",
    "model_seasonal = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=4,\n",
    "    min_samples_split=10,\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Effectuer la validation croisée pour le modèle Seasonal Vaccine\n",
    "cv_results_seasonal = cross_val_score(model_seasonal, X_train_seasonal, y_train_seasonal, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"\\nCross-Validation Results for Seasonal Vaccine Model:\")\n",
    "print(f\"Accuracy Scores per Fold: {cv_results_seasonal}\")\n",
    "print(f\"Mean Accuracy: {np.mean(cv_results_seasonal):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(cv_results_seasonal):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d015b871-a5e5-412d-903d-44a61ecf1e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from optuna) (1.13.2)\n",
      "Requirement already satisfied: colorlog in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from optuna) (23.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from optuna) (2.0.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-22 04:06:00,127] A new study created in memory with name: no-name-3e2afb74-8227-4387-b313-c1db296f0fa7\n",
      "[I 2024-08-22 04:06:40,102] Trial 0 finished with value: 0.844652468991341 and parameters: {'n_estimators': 380, 'max_depth': 33, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': 'log2', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.844652468991341.\n",
      "[I 2024-08-22 04:06:59,414] Trial 1 finished with value: 0.8307980341680319 and parameters: {'n_estimators': 169, 'max_depth': 30, 'min_samples_split': 19, 'min_samples_leaf': 5, 'max_features': 'log2', 'class_weight': 'balanced_subsample'}. Best is trial 0 with value: 0.844652468991341.\n",
      "[I 2024-08-22 04:07:21,560] Trial 2 finished with value: 0.8503159372805993 and parameters: {'n_estimators': 164, 'max_depth': 37, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': 'balanced_subsample'}. Best is trial 2 with value: 0.8503159372805993.\n",
      "[I 2024-08-22 04:08:01,103] Trial 3 finished with value: 0.8280833138310321 and parameters: {'n_estimators': 321, 'max_depth': 45, 'min_samples_split': 17, 'min_samples_leaf': 7, 'max_features': 'log2', 'class_weight': 'balanced_subsample'}. Best is trial 2 with value: 0.8503159372805993.\n",
      "[I 2024-08-22 04:08:33,596] Trial 4 finished with value: 0.8304235899836181 and parameters: {'n_estimators': 284, 'max_depth': 26, 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'class_weight': 'balanced_subsample'}. Best is trial 2 with value: 0.8503159372805993.\n",
      "[I 2024-08-22 04:09:16,472] Trial 5 finished with value: 0.8372571963491691 and parameters: {'n_estimators': 430, 'max_depth': 37, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 2 with value: 0.8503159372805993.\n",
      "[I 2024-08-22 04:09:45,450] Trial 6 finished with value: 0.8377252515796865 and parameters: {'n_estimators': 285, 'max_depth': 21, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 2 with value: 0.8503159372805993.\n",
      "[I 2024-08-22 04:10:27,325] Trial 7 finished with value: 0.8309384507371871 and parameters: {'n_estimators': 380, 'max_depth': 13, 'min_samples_split': 17, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'class_weight': 'balanced_subsample'}. Best is trial 2 with value: 0.8503159372805993.\n",
      "[I 2024-08-22 04:10:47,204] Trial 8 finished with value: 0.8335127545050316 and parameters: {'n_estimators': 196, 'max_depth': 49, 'min_samples_split': 12, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 2 with value: 0.8503159372805993.\n",
      "[I 2024-08-22 04:11:23,747] Trial 9 finished with value: 0.8485841329276855 and parameters: {'n_estimators': 311, 'max_depth': 37, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 2 with value: 0.8503159372805993.\n",
      "[I 2024-08-22 04:11:35,428] Trial 10 finished with value: 0.8216241516498947 and parameters: {'n_estimators': 107, 'max_depth': 42, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': 'log2', 'class_weight': 'balanced_subsample'}. Best is trial 2 with value: 0.8503159372805993.\n",
      "[I 2024-08-22 04:12:04,173] Trial 11 finished with value: 0.8519541305874092 and parameters: {'n_estimators': 221, 'max_depth': 38, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 11 with value: 0.8519541305874092.\n",
      "[I 2024-08-22 04:12:31,251] Trial 12 finished with value: 0.8510180201263748 and parameters: {'n_estimators': 205, 'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 11 with value: 0.8519541305874092.\n",
      "[I 2024-08-22 04:13:01,612] Trial 13 finished with value: 0.8507371869880644 and parameters: {'n_estimators': 228, 'max_depth': 43, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 11 with value: 0.8519541305874092.\n",
      "[I 2024-08-22 04:13:30,723] Trial 14 finished with value: 0.8497542710039785 and parameters: {'n_estimators': 222, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 11 with value: 0.8519541305874092.\n",
      "[I 2024-08-22 04:13:43,287] Trial 15 finished with value: 0.8444184413760825 and parameters: {'n_estimators': 116, 'max_depth': 48, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 11 with value: 0.8519541305874092.\n",
      "[I 2024-08-22 04:14:05,816] Trial 16 finished with value: 0.8208284577580155 and parameters: {'n_estimators': 246, 'max_depth': 40, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 11 with value: 0.8519541305874092.\n",
      "[I 2024-08-22 04:14:27,611] Trial 17 finished with value: 0.8507371869880647 and parameters: {'n_estimators': 176, 'max_depth': 31, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 11 with value: 0.8519541305874092.\n",
      "[I 2024-08-22 04:15:13,920] Trial 18 finished with value: 0.8256962321553942 and parameters: {'n_estimators': 497, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'log2', 'class_weight': 'balanced'}. Best is trial 11 with value: 0.8519541305874092.\n",
      "[I 2024-08-22 04:15:41,515] Trial 19 finished with value: 0.8446056634682894 and parameters: {'n_estimators': 259, 'max_depth': 34, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 11 with value: 0.8519541305874092.\n",
      "[I 2024-08-22 04:15:56,212] Trial 20 finished with value: 0.8420313597004446 and parameters: {'n_estimators': 137, 'max_depth': 46, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 11 with value: 0.8519541305874092.\n",
      "[I 2024-08-22 04:16:21,123] Trial 21 finished with value: 0.8508776035572196 and parameters: {'n_estimators': 192, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 11 with value: 0.8519541305874092.\n",
      "[I 2024-08-22 04:16:48,185] Trial 22 finished with value: 0.8524689913409784 and parameters: {'n_estimators': 219, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 22 with value: 0.8524689913409784.\n",
      "[I 2024-08-22 04:17:14,664] Trial 23 finished with value: 0.8522349637257196 and parameters: {'n_estimators': 216, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 22 with value: 0.8524689913409784.\n",
      "[I 2024-08-22 04:17:45,408] Trial 24 finished with value: 0.8529838520945472 and parameters: {'n_estimators': 257, 'max_depth': 21, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 24 with value: 0.8529838520945472.\n",
      "[I 2024-08-22 04:18:15,186] Trial 25 finished with value: 0.8476948279897026 and parameters: {'n_estimators': 269, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 24 with value: 0.8529838520945472.\n",
      "[I 2024-08-22 04:18:53,994] Trial 26 finished with value: 0.8422653873157031 and parameters: {'n_estimators': 360, 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'log2', 'class_weight': 'balanced'}. Best is trial 24 with value: 0.8529838520945472.\n",
      "[I 2024-08-22 04:19:34,920] Trial 27 finished with value: 0.8530306576175988 and parameters: {'n_estimators': 342, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 27 with value: 0.8530306576175988.\n",
      "[I 2024-08-22 04:20:12,113] Trial 28 finished with value: 0.8474139948513925 and parameters: {'n_estimators': 341, 'max_depth': 23, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 27 with value: 0.8530306576175988.\n",
      "[I 2024-08-22 04:20:59,004] Trial 29 finished with value: 0.8506903814650129 and parameters: {'n_estimators': 423, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2', 'class_weight': 'balanced'}. Best is trial 27 with value: 0.8530306576175988.\n",
      "[I 2024-08-22 04:21:30,161] Trial 30 finished with value: 0.8229815118183946 and parameters: {'n_estimators': 420, 'max_depth': 10, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 27 with value: 0.8530306576175988.\n",
      "[I 2024-08-22 04:22:00,892] Trial 31 finished with value: 0.8525157968640299 and parameters: {'n_estimators': 251, 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 27 with value: 0.8530306576175988.\n",
      "[I 2024-08-22 04:22:40,102] Trial 32 finished with value: 0.8526094079101334 and parameters: {'n_estimators': 329, 'max_depth': 28, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 27 with value: 0.8530306576175988.\n",
      "[I 2024-08-22 04:23:18,544] Trial 33 finished with value: 0.8517669084952025 and parameters: {'n_estimators': 335, 'max_depth': 29, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 27 with value: 0.8530306576175988.\n",
      "[I 2024-08-22 04:23:57,803] Trial 34 finished with value: 0.8490053826351509 and parameters: {'n_estimators': 288, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'class_weight': 'balanced_subsample'}. Best is trial 27 with value: 0.8530306576175988.\n",
      "[I 2024-08-22 04:24:39,562] Trial 35 finished with value: 0.8488181605429441 and parameters: {'n_estimators': 313, 'max_depth': 32, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': 'balanced_subsample'}. Best is trial 27 with value: 0.8530306576175988.\n",
      "[I 2024-08-22 04:25:15,838] Trial 36 finished with value: 0.8373040018722209 and parameters: {'n_estimators': 367, 'max_depth': 34, 'min_samples_split': 20, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 27 with value: 0.8530306576175988.\n",
      "[I 2024-08-22 04:25:56,997] Trial 37 finished with value: 0.8380060847179968 and parameters: {'n_estimators': 399, 'max_depth': 28, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'class_weight': 'balanced'}. Best is trial 27 with value: 0.8530306576175988.\n",
      "[I 2024-08-22 04:26:29,258] Trial 38 finished with value: 0.8452609407910133 and parameters: {'n_estimators': 251, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'class_weight': 'balanced_subsample'}. Best is trial 27 with value: 0.8530306576175988.\n",
      "[I 2024-08-22 04:27:12,849] Trial 39 finished with value: 0.8532178797098057 and parameters: {'n_estimators': 335, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'class_weight': 'balanced'}. Best is trial 39 with value: 0.8532178797098057.\n",
      "[I 2024-08-22 04:27:52,153] Trial 40 finished with value: 0.8328574771823074 and parameters: {'n_estimators': 333, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 'log2', 'class_weight': 'balanced_subsample'}. Best is trial 39 with value: 0.8532178797098057.\n",
      "[I 2024-08-22 04:28:30,285] Trial 41 finished with value: 0.8520009361104611 and parameters: {'n_estimators': 294, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2', 'class_weight': 'balanced'}. Best is trial 39 with value: 0.8532178797098057.\n",
      "[I 2024-08-22 04:29:11,904] Trial 42 finished with value: 0.8534051018020126 and parameters: {'n_estimators': 351, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'class_weight': 'balanced'}. Best is trial 42 with value: 0.8534051018020126.\n",
      "[I 2024-08-22 04:29:55,384] Trial 43 finished with value: 0.8498478820500818 and parameters: {'n_estimators': 393, 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2', 'class_weight': 'balanced'}. Best is trial 42 with value: 0.8534051018020126.\n",
      "[I 2024-08-22 04:30:34,344] Trial 44 finished with value: 0.847975661128013 and parameters: {'n_estimators': 349, 'max_depth': 22, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'log2', 'class_weight': 'balanced'}. Best is trial 42 with value: 0.8534051018020126.\n",
      "[I 2024-08-22 04:31:08,124] Trial 45 finished with value: 0.8431078867306342 and parameters: {'n_estimators': 319, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2', 'class_weight': 'balanced'}. Best is trial 42 with value: 0.8534051018020126.\n",
      "[I 2024-08-22 04:31:54,279] Trial 46 finished with value: 0.8530306576175988 and parameters: {'n_estimators': 373, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'class_weight': 'balanced'}. Best is trial 42 with value: 0.8534051018020126.\n",
      "[I 2024-08-22 04:32:43,903] Trial 47 finished with value: 0.8453545518371168 and parameters: {'n_estimators': 467, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2', 'class_weight': 'balanced'}. Best is trial 42 with value: 0.8534051018020126.\n",
      "[I 2024-08-22 04:33:19,046] Trial 48 finished with value: 0.8267727591855838 and parameters: {'n_estimators': 378, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_features': 'log2', 'class_weight': 'balanced'}. Best is trial 42 with value: 0.8534051018020126.\n",
      "[I 2024-08-22 04:34:09,120] Trial 49 finished with value: 0.8429206646384273 and parameters: {'n_estimators': 398, 'max_depth': 21, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'log2', 'class_weight': 'balanced_subsample'}. Best is trial 42 with value: 0.8534051018020126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 351, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparamètres que vous souhaitez optimiser\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 50)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2'])\n",
    "    class_weight = trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample'])\n",
    "\n",
    "    # Créer le modèle avec les hyperparamètres proposés\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        class_weight=class_weight,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Validation croisée pour évaluer la performance\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train_h1n1, y_train_h1n1, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    return cv_scores.mean()\n",
    "\n",
    "# Créer l'étude Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Meilleurs hyperparamètres trouvés par Optuna\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f685c0f1-542f-4568-af7e-dd75dff33c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Optimized H1N1 Vaccine Model:\n",
      "Training Time: 14.27 seconds\n",
      "Prediction Time: 0.67 seconds\n",
      "Accuracy: 0.85\n",
      "Confusion Matrix:\n",
      "[[3932  280]\n",
      " [ 527  603]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.93      0.91      4212\n",
      "         1.0       0.68      0.53      0.60      1130\n",
      "\n",
      "    accuracy                           0.85      5342\n",
      "   macro avg       0.78      0.73      0.75      5342\n",
      "weighted avg       0.84      0.85      0.84      5342\n",
      "\n",
      "\n",
      "Performance for Optimized Seasonal Vaccine Model:\n",
      "Training Time: 15.23 seconds\n",
      "Prediction Time: 0.85 seconds\n",
      "Accuracy: 0.79\n",
      "Confusion Matrix:\n",
      "[[2333  558]\n",
      " [ 581 1870]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.81      0.80      2891\n",
      "         1.0       0.77      0.76      0.77      2451\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.79      0.78      0.79      5342\n",
      "weighted avg       0.79      0.79      0.79      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "# Créer et entraîner le modèle Random Forest avec les hyperparamètres optimisés\n",
    "model_h1n1_optimized = RandomForestClassifier(\n",
    "    n_estimators=484,\n",
    "    max_depth=39,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Mesurer le temps d'entraînement\n",
    "start_time = time.time()\n",
    "model_h1n1_optimized.fit(X_train_h1n1, y_train_h1n1)\n",
    "training_time_h1n1 = time.time() - start_time\n",
    "\n",
    "# Mesurer le temps de prédiction\n",
    "start_time = time.time()\n",
    "y_pred_h1n1_optimized = model_h1n1_optimized.predict(X_test_h1n1)\n",
    "prediction_time_h1n1 = time.time() - start_time\n",
    "\n",
    "# Évaluer la performance du modèle optimisé\n",
    "print(\"Performance for Optimized H1N1 Vaccine Model:\")\n",
    "print(f\"Training Time: {training_time_h1n1:.2f} seconds\")\n",
    "print(f\"Prediction Time: {prediction_time_h1n1:.2f} seconds\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_h1n1, y_pred_h1n1_optimized):.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_h1n1, y_pred_h1n1_optimized))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_h1n1, y_pred_h1n1_optimized))\n",
    "\n",
    "# Créer et entraîner le modèle Random Forest avec les hyperparamètres optimisés pour Seasonal Vaccine\n",
    "model_seasonal_optimized = RandomForestClassifier(\n",
    "    n_estimators=484,\n",
    "    max_depth=39,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Mesurer le temps d'entraînement\n",
    "start_time = time.time()\n",
    "model_seasonal_optimized.fit(X_train_seasonal, y_train_seasonal)\n",
    "training_time_seasonal = time.time() - start_time\n",
    "\n",
    "# Mesurer le temps de prédiction\n",
    "start_time = time.time()\n",
    "y_pred_seasonal_optimized = model_seasonal_optimized.predict(X_test_seasonal)\n",
    "prediction_time_seasonal = time.time() - start_time\n",
    "\n",
    "# Évaluer la performance du modèle optimisé\n",
    "print(\"\\nPerformance for Optimized Seasonal Vaccine Model:\")\n",
    "print(f\"Training Time: {training_time_seasonal:.2f} seconds\")\n",
    "print(f\"Prediction Time: {prediction_time_seasonal:.2f} seconds\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_seasonal, y_pred_seasonal_optimized):.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_seasonal, y_pred_seasonal_optimized))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_seasonal, y_pred_seasonal_optimized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40bf4b77-6178-4106-b426-7c873e368854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seasonal_vaccine_rfmodel.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Enregistrer le modèle optimisé pour H1N1 Vaccine\n",
    "joblib.dump(model_h1n1_optimized, 'h1n1_vaccine_rfmodel.pkl')\n",
    "\n",
    "# Enregistrer le modèle optimisé pour Seasonal Vaccine\n",
    "joblib.dump(model_seasonal_optimized, 'seasonal_vaccine_rfmodel.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6291f31-18ea-4986-9ae8-51353f3b4dca",
   "metadata": {},
   "source": [
    "# Light GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e202b29-7dd4-4efa-9bec-073f5407288b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from imbalanced-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0ec77f0-615e-4bf6-9fc1-9a48e752b69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 729 candidates, totalling 2187 fits\n",
      "[LightGBM] [Info] Number of positive: 16793, number of negative: 16793\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8588\n",
      "[LightGBM] [Info] Number of data points in the train set: 33586, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Best Hyperparameters: {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'min_child_samples': 20, 'n_estimators': 200, 'num_leaves': 50, 'subsample': 0.8}\n",
      "Performance for Optimized h1n1_vaccine Model:\n",
      "Accuracy: 0.8491201797079745\n",
      "Confusion Matrix:\n",
      " [[3945  267]\n",
      " [ 539  591]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.94      0.91      4212\n",
      "         1.0       0.69      0.52      0.59      1130\n",
      "\n",
      "    accuracy                           0.85      5342\n",
      "   macro avg       0.78      0.73      0.75      5342\n",
      "weighted avg       0.84      0.85      0.84      5342\n",
      "\n",
      "Fitting 3 folds for each of 729 candidates, totalling 2187 fits\n",
      "[LightGBM] [Info] Number of positive: 10472, number of negative: 10472\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6518\n",
      "[LightGBM] [Info] Number of data points in the train set: 20944, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Best Hyperparameters for seasonal_vaccine: {'colsample_bytree': 0.9, 'learning_rate': 0.05, 'min_child_samples': 30, 'n_estimators': 200, 'num_leaves': 40, 'subsample': 0.8}\n",
      "\n",
      "Performance for Optimized seasonal_vaccine Model:\n",
      "Accuracy: 0.7890303257207039\n",
      "Confusion Matrix:\n",
      " [[2353  538]\n",
      " [ 589 1862]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.81      0.81      2891\n",
      "         1.0       0.78      0.76      0.77      2451\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.79      0.79      0.79      5342\n",
      "weighted avg       0.79      0.79      0.79      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Définir X et les deux cibles y_h1n1 et y_seasonal à partir de votre DataFrame d'entraînement\n",
    "X = df.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])  # Toutes les colonnes sauf les cibles\n",
    "y_h1n1 = df['h1n1_vaccine']  # Première cible\n",
    "y_seasonal = df['seasonal_vaccine']  # Deuxième cible\n",
    "\n",
    "# Séparer les données pour h1n1_vaccine avant l'application de SMOTETomek\n",
    "X_train_h1n1, X_val_h1n1, y_train_h1n1, y_val_h1n1 = train_test_split(X, y_h1n1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Appliquer SMOTETomek pour rééquilibrer les classes\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_h1n1_resampled, y_train_h1n1_resampled = smote_tomek.fit_resample(X_train_h1n1, y_train_h1n1)\n",
    "\n",
    "# Paramètres à optimiser pour LightGBM\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 40, 50],\n",
    "    'learning_rate': [0.05, 0.01, 0.1],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'min_child_samples': [20, 30, 40],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Créer le modèle LightGBM\n",
    "lgbm = lgb.LGBMClassifier(objective='binary', metric='binary_logloss', random_state=42)\n",
    "\n",
    "# Initialiser GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lgbm, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Entraîner le modèle avec GridSearchCV\n",
    "grid_search.fit(X_train_h1n1_resampled, y_train_h1n1_resampled)\n",
    "\n",
    "# Meilleurs hyperparamètres trouvés\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de validation avec le meilleur modèle\n",
    "best_model_h1n1 = grid_search.best_estimator_\n",
    "y_pred_h1n1 = best_model_h1n1.predict(X_val_h1n1)\n",
    "\n",
    "# Évaluation des performances pour h1n1_vaccine\n",
    "print(\"Performance for Optimized h1n1_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_h1n1, y_pred_h1n1))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_h1n1))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_h1n1))\n",
    "\n",
    "# Répéter le processus pour seasonal_vaccine\n",
    "\n",
    "# Séparer les données pour seasonal_vaccine avant l'application de SMOTETomek\n",
    "X_train_seasonal, X_val_seasonal, y_train_seasonal, y_val_seasonal = train_test_split(X, y_seasonal, test_size=0.2, random_state=42)\n",
    "\n",
    "# Appliquer SMOTETomek pour rééquilibrer les classes\n",
    "X_train_seasonal_resampled, y_train_seasonal_resampled = smote_tomek.fit_resample(X_train_seasonal, y_train_seasonal)\n",
    "\n",
    "# GridSearchCV pour seasonal_vaccine\n",
    "grid_search.fit(X_train_seasonal_resampled, y_train_seasonal_resampled)\n",
    "\n",
    "# Meilleurs hyperparamètres trouvés\n",
    "print(f\"Best Hyperparameters for seasonal_vaccine: {grid_search.best_params_}\")\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de validation avec le meilleur modèle\n",
    "best_model_seasonal = grid_search.best_estimator_\n",
    "y_pred_seasonal = best_model_seasonal.predict(X_val_seasonal)\n",
    "\n",
    "# Évaluation des performances pour seasonal_vaccine\n",
    "print(\"\\nPerformance for Optimized seasonal_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_seasonal, y_pred_seasonal))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_seasonal, y_pred_seasonal))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_seasonal, y_pred_seasonal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dd23ae7-23cc-4530-962c-39ff206cba92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seasonal_vaccine_lgbmmodel.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Enregistrer le modèle optimisé pour H1N1 Vaccine\n",
    "joblib.dump(best_model_h1n1, 'h1n1_vaccine_lgbmmodel.pkl')\n",
    "\n",
    "# Enregistrer le modèle optimisé pour Seasonal Vaccine\n",
    "joblib.dump(best_model_seasonal, 'seasonal_vaccine_lgbmmodel.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de402f3-851e-4efe-a038-11dc3013cb96",
   "metadata": {},
   "source": [
    "# Gradient Boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f614126-8321-4779-8e2a-5e790f733a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for GBM h1n1_vaccine Model:\n",
      "Accuracy: 0.8498689629352303\n",
      "Confusion Matrix:\n",
      " [[3954  258]\n",
      " [ 544  586]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.94      0.91      4212\n",
      "         1.0       0.69      0.52      0.59      1130\n",
      "\n",
      "    accuracy                           0.85      5342\n",
      "   macro avg       0.79      0.73      0.75      5342\n",
      "weighted avg       0.84      0.85      0.84      5342\n",
      "\n",
      "\n",
      "Performance for GBM seasonal_vaccine Model:\n",
      "Accuracy: 0.7901535005615874\n",
      "Confusion Matrix:\n",
      " [[2355  536]\n",
      " [ 585 1866]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.81      0.81      2891\n",
      "         1.0       0.78      0.76      0.77      2451\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.79      0.79      0.79      5342\n",
      "weighted avg       0.79      0.79      0.79      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Entraîner un modèle Gradient Boosting sur les données rééchantillonnées\n",
    "gbm_model_h1n1 = GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "gbm_model_h1n1.fit(X_train_h1n1_resampled, y_train_h1n1_resampled)\n",
    "\n",
    "# Prédictions et évaluation\n",
    "y_pred_gbm_h1n1 = gbm_model_h1n1.predict(X_val_h1n1)\n",
    "print(\"Performance for GBM h1n1_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_h1n1, y_pred_gbm_h1n1))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_gbm_h1n1))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_gbm_h1n1))\n",
    "\n",
    "# Répéter pour seasonal_vaccine\n",
    "gbm_model_seasonal = GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "gbm_model_seasonal.fit(X_train_seasonal_resampled, y_train_seasonal_resampled)\n",
    "y_pred_gbm_seasonal = gbm_model_seasonal.predict(X_val_seasonal)\n",
    "print(\"\\nPerformance for GBM seasonal_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_seasonal, y_pred_gbm_seasonal))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_seasonal, y_pred_gbm_seasonal))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_seasonal, y_pred_gbm_seasonal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cece5f65-57b6-4105-8c83-98b7a3491285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seasonal_vaccine_gbmmodel.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Enregistrer le modèle optimisé pour H1N1 Vaccine\n",
    "joblib.dump(gbm_model_h1n1, 'h1n1_vaccine_gbmmodel.pkl')\n",
    "\n",
    "# Enregistrer le modèle optimisé pour Seasonal Vaccine\n",
    "joblib.dump(gbm_model_seasonal, 'seasonal_vaccine_gbmmodel.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a21f90a-adb0-436a-a143-cb56a74574ed",
   "metadata": {},
   "source": [
    "# Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1f2a1f2-54b2-4857-8cd9-ea077bd73250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16793, number of negative: 16793\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8588\n",
      "[LightGBM] [Info] Number of data points in the train set: 33586, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 13434, number of negative: 13434\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8589\n",
      "[LightGBM] [Info] Number of data points in the train set: 26868, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 13435, number of negative: 13434\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8563\n",
      "[LightGBM] [Info] Number of data points in the train set: 26869, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000074\n",
      "[LightGBM] [Info] Start training from score 0.000074\n",
      "[LightGBM] [Info] Number of positive: 13435, number of negative: 13434\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8384\n",
      "[LightGBM] [Info] Number of data points in the train set: 26869, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000074\n",
      "[LightGBM] [Info] Start training from score 0.000074\n",
      "[LightGBM] [Info] Number of positive: 13434, number of negative: 13435\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8381\n",
      "[LightGBM] [Info] Number of data points in the train set: 26869, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499981 -> initscore=-0.000074\n",
      "[LightGBM] [Info] Start training from score -0.000074\n",
      "[LightGBM] [Info] Number of positive: 13434, number of negative: 13435\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8380\n",
      "[LightGBM] [Info] Number of data points in the train set: 26869, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499981 -> initscore=-0.000074\n",
      "[LightGBM] [Info] Start training from score -0.000074\n",
      "Performance for Stacking h1n1_vaccine Model:\n",
      "Accuracy: 0.8446274803444402\n",
      "Confusion Matrix:\n",
      " [[3914  298]\n",
      " [ 532  598]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.93      0.90      4212\n",
      "         1.0       0.67      0.53      0.59      1130\n",
      "\n",
      "    accuracy                           0.84      5342\n",
      "   macro avg       0.77      0.73      0.75      5342\n",
      "weighted avg       0.84      0.84      0.84      5342\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 10472, number of negative: 10472\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6518\n",
      "[LightGBM] [Info] Number of data points in the train set: 20944, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 8378, number of negative: 8377\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6520\n",
      "[LightGBM] [Info] Number of data points in the train set: 16755, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500030 -> initscore=0.000119\n",
      "[LightGBM] [Info] Start training from score 0.000119\n",
      "[LightGBM] [Info] Number of positive: 8378, number of negative: 8377\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6519\n",
      "[LightGBM] [Info] Number of data points in the train set: 16755, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500030 -> initscore=0.000119\n",
      "[LightGBM] [Info] Start training from score 0.000119\n",
      "[LightGBM] [Info] Number of positive: 8377, number of negative: 8378\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6519\n",
      "[LightGBM] [Info] Number of data points in the train set: 16755, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499970 -> initscore=-0.000119\n",
      "[LightGBM] [Info] Start training from score -0.000119\n",
      "[LightGBM] [Info] Number of positive: 8377, number of negative: 8378\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6519\n",
      "[LightGBM] [Info] Number of data points in the train set: 16755, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499970 -> initscore=-0.000119\n",
      "[LightGBM] [Info] Start training from score -0.000119\n",
      "[LightGBM] [Info] Number of positive: 8378, number of negative: 8378\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 16756, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "Performance for Stacking seasonal_vaccine Model:\n",
      "Accuracy: 0.7884687383002621\n",
      "Confusion Matrix:\n",
      " [[2325  566]\n",
      " [ 564 1887]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.80      0.80      2891\n",
      "         1.0       0.77      0.77      0.77      2451\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.79      0.79      0.79      5342\n",
      "weighted avg       0.79      0.79      0.79      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Pour h1n1_vaccine\n",
    "# Définir les modèles de base\n",
    "estimators_h1n1 = [\n",
    "    ('rf', model_h1n1_optimized),  # Random Forest optimisé\n",
    "    ('lgbm', best_model_h1n1),     # LightGBM optimisé\n",
    "    ('gbm', gbm_model_h1n1)        # GBM que vous venez d'entraîner\n",
    "]\n",
    "\n",
    "# Modèle de stacking pour h1n1_vaccine\n",
    "stacking_model_h1n1 = StackingClassifier(estimators=estimators_h1n1, final_estimator=LogisticRegression())\n",
    "\n",
    "# Entraîner le modèle de stacking sur les données rééchantillonnées\n",
    "stacking_model_h1n1.fit(X_train_h1n1_resampled, y_train_h1n1_resampled)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de validation pour h1n1_vaccine\n",
    "y_pred_stack_h1n1 = stacking_model_h1n1.predict(X_val_h1n1)\n",
    "\n",
    "# Évaluation des performances pour le modèle de stacking h1n1_vaccine\n",
    "print(\"Performance for Stacking h1n1_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_h1n1, y_pred_stack_h1n1))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_stack_h1n1))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_stack_h1n1))\n",
    "\n",
    "# Pour seasonal_vaccine\n",
    "# Définir les modèles de base\n",
    "estimators_seasonal = [\n",
    "    ('rf', model_seasonal_optimized),  # Random Forest optimisé\n",
    "    ('lgbm', best_model_seasonal),     # LightGBM optimisé\n",
    "    ('gbm', gbm_model_seasonal)        # GBM que vous venez d'entraîner\n",
    "]\n",
    "\n",
    "# Modèle de stacking pour seasonal_vaccine\n",
    "stacking_model_seasonal = StackingClassifier(estimators=estimators_seasonal, final_estimator=LogisticRegression())\n",
    "\n",
    "# Entraîner le modèle de stacking sur les données rééchantillonnées\n",
    "stacking_model_seasonal.fit(X_train_seasonal_resampled, y_train_seasonal_resampled)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de validation pour seasonal_vaccine\n",
    "y_pred_stack_seasonal = stacking_model_seasonal.predict(X_val_seasonal)\n",
    "\n",
    "# Évaluation des performances pour le modèle de stacking seasonal_vaccine\n",
    "print(\"\\nPerformance for Stacking seasonal_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_seasonal, y_pred_stack_seasonal))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_seasonal, y_pred_stack_seasonal))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_seasonal, y_pred_stack_seasonal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da71f3c0-b6df-49d6-81b3-0efb3a7f7684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\loris\\\\Desktop\\\\Flu_Prediction_Project\\\\stacking_seasonal_vaccine_model.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Spécifier le chemin du dossier\n",
    "folder_path = r\"C:\\Users\\loris\\Desktop\\Flu_Prediction_Project\"\n",
    "\n",
    "# Exporter le modèle de stacking pour h1n1_vaccine\n",
    "joblib.dump(stacking_model_h1n1, f\"{folder_path}\\\\stacking_h1n1_vaccine_model.pkl\")\n",
    "\n",
    "# Exporter le modèle de stacking pour seasonal_vaccine\n",
    "joblib.dump(stacking_model_seasonal, f\"{folder_path}\\\\stacking_seasonal_vaccine_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71e0fa9-a1da-4fea-88de-14d08dfdc04d",
   "metadata": {},
   "source": [
    "# Stacking avancé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16339d22-be18-43e7-99c9-6ae16d60713c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16793, number of negative: 16793\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8588\n",
      "[LightGBM] [Info] Number of data points in the train set: 33586, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 13434, number of negative: 13434\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8589\n",
      "[LightGBM] [Info] Number of data points in the train set: 26868, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 13435, number of negative: 13434\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8563\n",
      "[LightGBM] [Info] Number of data points in the train set: 26869, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000074\n",
      "[LightGBM] [Info] Start training from score 0.000074\n",
      "[LightGBM] [Info] Number of positive: 13435, number of negative: 13434\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8384\n",
      "[LightGBM] [Info] Number of data points in the train set: 26869, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000074\n",
      "[LightGBM] [Info] Start training from score 0.000074\n",
      "[LightGBM] [Info] Number of positive: 13434, number of negative: 13435\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8381\n",
      "[LightGBM] [Info] Number of data points in the train set: 26869, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499981 -> initscore=-0.000074\n",
      "[LightGBM] [Info] Start training from score -0.000074\n",
      "[LightGBM] [Info] Number of positive: 13434, number of negative: 13435\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8380\n",
      "[LightGBM] [Info] Number of data points in the train set: 26869, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499981 -> initscore=-0.000074\n",
      "[LightGBM] [Info] Start training from score -0.000074\n",
      "Advanced Stacking Model Accuracy: 0.8476226132534631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Modèle de stacking avancé pour h1n1_vaccine avec un GBM comme modèle final\n",
    "stacking_model_h1n1_advanced = StackingClassifier(\n",
    "    estimators=estimators_h1n1, \n",
    "    final_estimator=GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, max_depth=3)\n",
    ")\n",
    "\n",
    "# Entraîner le modèle de stacking avancé\n",
    "stacking_model_h1n1_advanced.fit(X_train_h1n1_resampled, y_train_h1n1_resampled)\n",
    "\n",
    "# Prédictions et évaluation\n",
    "y_pred_advanced = stacking_model_h1n1_advanced.predict(X_val_h1n1)\n",
    "print(\"Advanced Stacking Model Accuracy:\", accuracy_score(y_val_h1n1, y_pred_advanced))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2748b82d-51e1-4fed-86e7-5ca0ce33d896",
   "metadata": {},
   "source": [
    "# Ensemble Learning avec Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98bb6b1b-ae4b-4805-a4b4-89901d50ff4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16793, number of negative: 16793\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8588\n",
      "[LightGBM] [Info] Number of data points in the train set: 33586, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Performance for Voting Classifier h1n1_vaccine Model:\n",
      "Accuracy: 0.8491201797079745\n",
      "Confusion Matrix:\n",
      " [[3975  237]\n",
      " [ 569  561]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.94      0.91      4212\n",
      "         1.0       0.70      0.50      0.58      1130\n",
      "\n",
      "    accuracy                           0.85      5342\n",
      "   macro avg       0.79      0.72      0.74      5342\n",
      "weighted avg       0.84      0.85      0.84      5342\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 10472, number of negative: 10472\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6518\n",
      "[LightGBM] [Info] Number of data points in the train set: 20944, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "Performance for Voting Classifier seasonal_vaccine Model:\n",
      "Accuracy: 0.7899663047547735\n",
      "Confusion Matrix:\n",
      " [[2357  534]\n",
      " [ 588 1863]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.82      0.81      2891\n",
      "         1.0       0.78      0.76      0.77      2451\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.79      0.79      0.79      5342\n",
      "weighted avg       0.79      0.79      0.79      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Modèles existants\n",
    "rf_model = model_h1n1_optimized         # Modèle Random Forest optimisé\n",
    "lgbm_model = best_model_h1n1            # Modèle LightGBM optimisé\n",
    "gbm_model = gbm_model_h1n1              # Modèle Gradient Boosting Machine\n",
    "\n",
    "# Créer un Voting Classifier pour h1n1_vaccine\n",
    "voting_clf_h1n1 = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model),\n",
    "        ('lgbm', lgbm_model),\n",
    "        ('gbm', gbm_model)\n",
    "    ],\n",
    "    voting='soft'  # Utilisez 'hard' pour le voting dur, ou 'soft' pour le voting par probabilité\n",
    ")\n",
    "\n",
    "# Entraîner le Voting Classifier\n",
    "voting_clf_h1n1.fit(X_train_h1n1_resampled, y_train_h1n1_resampled)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de validation pour h1n1_vaccine\n",
    "y_pred_voting_h1n1 = voting_clf_h1n1.predict(X_val_h1n1)\n",
    "\n",
    "# Évaluation des performances\n",
    "print(\"Performance for Voting Classifier h1n1_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_h1n1, y_pred_voting_h1n1))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_voting_h1n1))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_voting_h1n1))\n",
    "\n",
    "# Répéter pour seasonal_vaccine\n",
    "rf_model_seasonal = model_seasonal_optimized\n",
    "lgbm_model_seasonal = best_model_seasonal\n",
    "gbm_model_seasonal = gbm_model_seasonal\n",
    "\n",
    "voting_clf_seasonal = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_model_seasonal),\n",
    "        ('lgbm', lgbm_model_seasonal),\n",
    "        ('gbm', gbm_model_seasonal)\n",
    "    ],\n",
    "    voting='soft'  # Utilisez 'hard' pour le voting dur, ou 'soft' pour le voting par probabilité\n",
    ")\n",
    "\n",
    "# Entraîner le Voting Classifier pour seasonal_vaccine\n",
    "voting_clf_seasonal.fit(X_train_seasonal_resampled, y_train_seasonal_resampled)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de validation pour seasonal_vaccine\n",
    "y_pred_voting_seasonal = voting_clf_seasonal.predict(X_val_seasonal)\n",
    "\n",
    "# Évaluation des performances\n",
    "print(\"\\nPerformance for Voting Classifier seasonal_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_seasonal, y_pred_voting_seasonal))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_seasonal, y_pred_voting_seasonal))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_seasonal, y_pred_voting_seasonal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bad66bc-432a-4a91-9a61-a5112b311f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle h1n1_vaccine_voting a été enregistré sous le nom 'h1n1_vaccine_voting.pkl'.\n",
      "Le modèle seasonal_vaccine_voting a été enregistré sous le nom 'seasonal_vaccine_voting.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Exporter le modèle Voting Classifier pour h1n1_vaccine\n",
    "joblib.dump(voting_clf_h1n1, \"h1n1_vaccine_voting.pkl\")\n",
    "print(\"Le modèle h1n1_vaccine_voting a été enregistré sous le nom 'h1n1_vaccine_voting.pkl'.\")\n",
    "\n",
    "# Exporter le modèle Voting Classifier pour seasonal_vaccine\n",
    "joblib.dump(voting_clf_seasonal, \"seasonal_vaccine_voting.pkl\")\n",
    "print(\"Le modèle seasonal_vaccine_voting a été enregistré sous le nom 'seasonal_vaccine_voting.pkl'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d42f92-2898-44a7-9e99-8797f3afb43b",
   "metadata": {},
   "source": [
    "# SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08bb8cd2-ecb8-4084-aeb9-1e30157f3d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8489329839011606\n",
      "Confusion Matrix:\n",
      " [[4009  203]\n",
      " [ 604  526]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91      4212\n",
      "         1.0       0.72      0.47      0.57      1130\n",
      "\n",
      "    accuracy                           0.85      5342\n",
      "   macro avg       0.80      0.71      0.74      5342\n",
      "weighted avg       0.84      0.85      0.84      5342\n",
      "\n",
      "\n",
      "Performance for seasonal_vaccine Model:\n",
      "Accuracy: 0.7787345563459378\n",
      "Confusion Matrix:\n",
      " [[2343  548]\n",
      " [ 634 1817]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.81      0.80      2891\n",
      "         1.0       0.77      0.74      0.75      2451\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.78      0.78      0.78      5342\n",
      "weighted avg       0.78      0.78      0.78      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Charger vos données et cibles\n",
    "X = df.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])\n",
    "y_h1n1 = df['h1n1_vaccine']\n",
    "y_seasonal = df['seasonal_vaccine']\n",
    "\n",
    "# Séparer les données en ensemble d'entraînement et de validation\n",
    "X_train_h1n1, X_val_h1n1, y_train_h1n1, y_val_h1n1 = train_test_split(X, y_h1n1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Appliquer SMOTETomek pour rééquilibrer les classes\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_h1n1_resampled, y_train_h1n1_resampled = smote_tomek.fit_resample(X_train_h1n1, y_train_h1n1)\n",
    "\n",
    "# Entraîner un modèle (par exemple Random Forest) sur les données rééquilibrées\n",
    "model_h1n1 = RandomForestClassifier(random_state=42)\n",
    "model_h1n1.fit(X_train_h1n1_resampled, y_train_h1n1_resampled)\n",
    "\n",
    "# Prédictions et évaluation sur l'ensemble de validation\n",
    "y_pred_h1n1 = model_h1n1.predict(X_val_h1n1)\n",
    "print(\"Accuracy:\", accuracy_score(y_val_h1n1, y_pred_h1n1))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_h1n1))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_h1n1))\n",
    "\n",
    "# Répéter pour seasonal_vaccine\n",
    "X_train_seasonal, X_val_seasonal, y_train_seasonal, y_val_seasonal = train_test_split(X, y_seasonal, test_size=0.2, random_state=42)\n",
    "X_train_seasonal_resampled, y_train_seasonal_resampled = smote_tomek.fit_resample(X_train_seasonal, y_train_seasonal)\n",
    "model_seasonal = RandomForestClassifier(random_state=42)\n",
    "model_seasonal.fit(X_train_seasonal_resampled, y_train_seasonal_resampled)\n",
    "y_pred_seasonal = model_seasonal.predict(X_val_seasonal)\n",
    "\n",
    "# Évaluation des performances pour seasonal_vaccine\n",
    "print(\"\\nPerformance for seasonal_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_seasonal, y_pred_seasonal))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_seasonal, y_pred_seasonal))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_seasonal, y_pred_seasonal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "410a231a-6a69-4b39-a2dd-868f803e5978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\loris\\\\Desktop\\\\Flu_Prediction_Project\\\\smote_seasonal_vaccine_model.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Spécifier le chemin du dossier\n",
    "folder_path = r\"C:\\Users\\loris\\Desktop\\Flu_Prediction_Project\"\n",
    "\n",
    "# Exporter le modèle pour h1n1_vaccine\n",
    "joblib.dump(model_h1n1, f\"{folder_path}\\\\smote_h1n1_vaccine_model.pkl\")\n",
    "\n",
    "# Exporter le modèle pour seasonal_vaccine\n",
    "joblib.dump(model_seasonal, f\"{folder_path}\\\\smote_seasonal_vaccine_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f7a110-c273-43e0-8b6d-3def66c57821",
   "metadata": {},
   "source": [
    "# XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11368c56-2746-4f8e-a4ce-b8ef44185de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for XGBoost h1n1_vaccine Model:\n",
      "Accuracy: 0.8515537251965556\n",
      "Confusion Matrix:\n",
      " [[3947  265]\n",
      " [ 528  602]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.94      0.91      4212\n",
      "         1.0       0.69      0.53      0.60      1130\n",
      "\n",
      "    accuracy                           0.85      5342\n",
      "   macro avg       0.79      0.73      0.76      5342\n",
      "weighted avg       0.84      0.85      0.84      5342\n",
      "\n",
      "\n",
      "Performance for XGBoost seasonal_vaccine Model:\n",
      "Accuracy: 0.7811681018345189\n",
      "Confusion Matrix:\n",
      " [[2319  572]\n",
      " [ 597 1854]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.80      0.80      2891\n",
      "         1.0       0.76      0.76      0.76      2451\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.78      0.78      0.78      5342\n",
      "weighted avg       0.78      0.78      0.78      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Créer et configurer un modèle XGBoost\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    scale_pos_weight=len(y_train_h1n1_resampled[y_train_h1n1_resampled == 0]) / len(y_train_h1n1_resampled[y_train_h1n1_resampled == 1]),\n",
    "    objective='binary:logistic',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Entraîner le modèle XGBoost\n",
    "xgb_model.fit(X_train_h1n1_resampled, y_train_h1n1_resampled)\n",
    "\n",
    "# Faire des prédictions\n",
    "y_pred_h1n1_xgb = xgb_model.predict(X_val_h1n1)\n",
    "\n",
    "# Évaluation des performances\n",
    "print(\"Performance for XGBoost h1n1_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_h1n1, y_pred_h1n1_xgb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_h1n1_xgb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_h1n1_xgb))\n",
    "\n",
    "# Répéter pour seasonal_vaccine\n",
    "xgb_model_seasonal = xgb.XGBClassifier(\n",
    "    scale_pos_weight=len(y_train_seasonal_resampled[y_train_seasonal_resampled == 0]) / len(y_train_seasonal_resampled[y_train_seasonal_resampled == 1]),\n",
    "    objective='binary:logistic',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_model_seasonal.fit(X_train_seasonal_resampled, y_train_seasonal_resampled)\n",
    "y_pred_seasonal_xgb = xgb_model_seasonal.predict(X_val_seasonal)\n",
    "\n",
    "# Évaluation des performances pour seasonal_vaccine\n",
    "print(\"\\nPerformance for XGBoost seasonal_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_seasonal, y_pred_seasonal_xgb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_seasonal, y_pred_seasonal_xgb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_seasonal, y_pred_seasonal_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a15db5b-a50e-407b-bd78-a15ba035e26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\loris\\\\Desktop\\\\Flu_Prediction_Project\\\\seasonal_vaccine_xgbmodel.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spécifier le chemin du dossier\n",
    "folder_path = r\"C:\\Users\\loris\\Desktop\\Flu_Prediction_Project\"\n",
    "\n",
    "# Exporter le modèle  pour h1n1_vaccine\n",
    "joblib.dump(xgb_model, f\"{folder_path}\\\\h1n1_vaccine_xgbmodel.pkl\")\n",
    "\n",
    "# Exporter le modèle pour seasonal_vaccine\n",
    "joblib.dump(xgb_model_seasonal, f\"{folder_path}\\\\seasonal_vaccine_xgbmodel.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6923804c-33f6-47f9-ae47-1a6c15325136",
   "metadata": {},
   "source": [
    "# Ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24d27636-05f3-4d9a-a249-d65560d90409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for AdaBoost h1n1_vaccine Model:\n",
      "Accuracy: 0.8429427180831149\n",
      "Confusion Matrix:\n",
      " [[3843  369]\n",
      " [ 470  660]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.91      0.90      4212\n",
      "         1.0       0.64      0.58      0.61      1130\n",
      "\n",
      "    accuracy                           0.84      5342\n",
      "   macro avg       0.77      0.75      0.76      5342\n",
      "weighted avg       0.84      0.84      0.84      5342\n",
      "\n",
      "\n",
      "Performance for AdaBoost seasonal_vaccine Model:\n",
      "Accuracy: 0.7821040808685885\n",
      "Confusion Matrix:\n",
      " [[2342  549]\n",
      " [ 615 1836]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.81      0.80      2891\n",
      "         1.0       0.77      0.75      0.76      2451\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.78      0.78      0.78      5342\n",
      "weighted avg       0.78      0.78      0.78      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Créer et configurer un modèle AdaBoost\n",
    "ada_model = AdaBoostClassifier(\n",
    "    n_estimators=100,  # Nombre d'estimateurs faibles\n",
    "    learning_rate=0.5  # Taux d'apprentissage\n",
    ")\n",
    "\n",
    "# Entraîner le modèle AdaBoost\n",
    "ada_model.fit(X_train_h1n1_resampled, y_train_h1n1_resampled)\n",
    "\n",
    "# Faire des prédictions\n",
    "y_pred_h1n1_ada = ada_model.predict(X_val_h1n1)\n",
    "\n",
    "# Évaluation des performances\n",
    "print(\"Performance for AdaBoost h1n1_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_h1n1, y_pred_h1n1_ada))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_h1n1_ada))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_h1n1_ada))\n",
    "\n",
    "# Répéter pour seasonal_vaccine\n",
    "ada_model_seasonal = AdaBoostClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.5\n",
    ")\n",
    "\n",
    "ada_model_seasonal.fit(X_train_seasonal_resampled, y_train_seasonal_resampled)\n",
    "y_pred_seasonal_ada = ada_model_seasonal.predict(X_val_seasonal)\n",
    "\n",
    "# Évaluation des performances pour seasonal_vaccine\n",
    "print(\"\\nPerformance for AdaBoost seasonal_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_seasonal, y_pred_seasonal_ada))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_seasonal, y_pred_seasonal_ada))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_seasonal, y_pred_seasonal_ada))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9e988f0-60de-4504-8650-9dd7522d8140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\loris\\\\Desktop\\\\Flu_Prediction_Project\\\\seasonal_vaccine_adamodel.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spécifier le chemin du dossier\n",
    "folder_path = r\"C:\\Users\\loris\\Desktop\\Flu_Prediction_Project\"\n",
    "\n",
    "# Exporter le modèle  pour h1n1_vaccine\n",
    "joblib.dump(ada_model, f\"{folder_path}\\\\h1n1_vaccine_adamodel.pkl\")\n",
    "\n",
    "# Exporter le modèle pour seasonal_vaccine\n",
    "joblib.dump(ada_model_seasonal, f\"{folder_path}\\\\seasonal_vaccine_adamodel.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2606c29f-493b-4d36-b25d-44678d38c497",
   "metadata": {},
   "source": [
    "# Stacking avancé bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3c8ea61-cac8-41b5-afb1-103983b40f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Stacked h1n1_vaccine Model:\n",
      "Accuracy: 0.8545488581055785\n",
      "Confusion Matrix:\n",
      " [[4024  188]\n",
      " [ 589  541]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.96      0.91      4212\n",
      "         1.0       0.74      0.48      0.58      1130\n",
      "\n",
      "    accuracy                           0.85      5342\n",
      "   macro avg       0.81      0.72      0.75      5342\n",
      "weighted avg       0.84      0.85      0.84      5342\n",
      "\n",
      "\n",
      "Performance for Stacked seasonal_vaccine Model:\n",
      "Accuracy: 0.7905278921752152\n",
      "Confusion Matrix:\n",
      " [[2371  520]\n",
      " [ 599 1852]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.82      0.81      2891\n",
      "         1.0       0.78      0.76      0.77      2451\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.79      0.79      0.79      5342\n",
      "weighted avg       0.79      0.79      0.79      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Charger vos données\n",
    "X = df.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])\n",
    "y_h1n1 = df['h1n1_vaccine']\n",
    "y_seasonal = df['seasonal_vaccine']\n",
    "\n",
    "# Séparer les données en ensemble d'entraînement et de validation\n",
    "X_train_h1n1, X_val_h1n1, y_train_h1n1, y_val_h1n1 = train_test_split(X, y_h1n1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Définir les modèles de base\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('xgb', xgb.XGBClassifier(scale_pos_weight=len(y_train_h1n1[y_train_h1n1 == 0]) / len(y_train_h1n1[y_train_h1n1 == 1]), random_state=42)),\n",
    "    ('ada', AdaBoostClassifier(n_estimators=100, learning_rate=0.5, random_state=42)),\n",
    "]\n",
    "\n",
    "# Modèle de niveau supérieur\n",
    "level_2_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, random_state=42)\n",
    "\n",
    "# Créer le Stacking Classifier\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=level_2_model, cv=5)\n",
    "\n",
    "# Entraîner le modèle empilé pour h1n1_vaccine\n",
    "stacking_model.fit(X_train_h1n1, y_train_h1n1)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de validation pour h1n1_vaccine\n",
    "y_pred_h1n1 = stacking_model.predict(X_val_h1n1)\n",
    "\n",
    "# Évaluation des performances pour h1n1_vaccine\n",
    "print(\"Performance for Stacked h1n1_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_h1n1, y_pred_h1n1))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_h1n1))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_h1n1))\n",
    "\n",
    "# Répéter les mêmes étapes pour seasonal_vaccine\n",
    "X_train_seasonal, X_val_seasonal, y_train_seasonal, y_val_seasonal = train_test_split(X, y_seasonal, test_size=0.2, random_state=42)\n",
    "\n",
    "stacking_model_seasonal = StackingClassifier(estimators=base_models, final_estimator=level_2_model, cv=5)\n",
    "stacking_model_seasonal.fit(X_train_seasonal, y_train_seasonal)\n",
    "\n",
    "y_pred_seasonal = stacking_model_seasonal.predict(X_val_seasonal)\n",
    "\n",
    "# Évaluation des performances pour seasonal_vaccine\n",
    "print(\"\\nPerformance for Stacked seasonal_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_seasonal, y_pred_seasonal))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_seasonal, y_pred_seasonal))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_seasonal, y_pred_seasonal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec7f3f0-9ba3-4129-820d-23fb56181071",
   "metadata": {},
   "source": [
    "# Neuronal network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed452429-3a79-4587-b2a6-fa3a3878b8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.65.5)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\loris\\documents\\anaconda\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loris\\Documents\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7878 - loss: 0.4876 - val_accuracy: 0.8317 - val_loss: 0.3964\n",
      "Epoch 2/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.3967 - val_accuracy: 0.8446 - val_loss: 0.3719\n",
      "Epoch 3/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8401 - loss: 0.3782 - val_accuracy: 0.8476 - val_loss: 0.3646\n",
      "Epoch 4/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8526 - loss: 0.3551 - val_accuracy: 0.8474 - val_loss: 0.3633\n",
      "Epoch 5/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8561 - loss: 0.3503 - val_accuracy: 0.8501 - val_loss: 0.3577\n",
      "Epoch 6/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8536 - loss: 0.3614 - val_accuracy: 0.8493 - val_loss: 0.3704\n",
      "Epoch 7/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8506 - loss: 0.3657 - val_accuracy: 0.8504 - val_loss: 0.3533\n",
      "Epoch 8/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8573 - loss: 0.3500 - val_accuracy: 0.8495 - val_loss: 0.3564\n",
      "Epoch 9/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.3486 - val_accuracy: 0.8519 - val_loss: 0.3580\n",
      "Epoch 10/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8581 - loss: 0.3446 - val_accuracy: 0.8491 - val_loss: 0.3596\n",
      "Epoch 11/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8559 - loss: 0.3451 - val_accuracy: 0.8499 - val_loss: 0.3582\n",
      "Epoch 12/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8608 - loss: 0.3378 - val_accuracy: 0.8512 - val_loss: 0.3598\n",
      "Epoch 13/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8595 - loss: 0.3420 - val_accuracy: 0.8497 - val_loss: 0.3601\n",
      "Epoch 14/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8586 - loss: 0.3435 - val_accuracy: 0.8508 - val_loss: 0.3553\n",
      "Epoch 15/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.3311 - val_accuracy: 0.8514 - val_loss: 0.3670\n",
      "Epoch 16/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8624 - loss: 0.3347 - val_accuracy: 0.8424 - val_loss: 0.3623\n",
      "Epoch 17/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8625 - loss: 0.3315 - val_accuracy: 0.8491 - val_loss: 0.3584\n",
      "Epoch 18/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8690 - loss: 0.3306 - val_accuracy: 0.8472 - val_loss: 0.3642\n",
      "Epoch 19/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.3265 - val_accuracy: 0.8486 - val_loss: 0.3614\n",
      "Epoch 20/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8671 - loss: 0.3249 - val_accuracy: 0.8517 - val_loss: 0.3643\n",
      "Epoch 21/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8643 - loss: 0.3306 - val_accuracy: 0.8489 - val_loss: 0.3616\n",
      "Epoch 22/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8670 - loss: 0.3286 - val_accuracy: 0.8469 - val_loss: 0.3622\n",
      "Epoch 23/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.3226 - val_accuracy: 0.8480 - val_loss: 0.3640\n",
      "Epoch 24/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8664 - loss: 0.3231 - val_accuracy: 0.8486 - val_loss: 0.3655\n",
      "Epoch 25/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8682 - loss: 0.3259 - val_accuracy: 0.8495 - val_loss: 0.3647\n",
      "Epoch 26/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8696 - loss: 0.3190 - val_accuracy: 0.8489 - val_loss: 0.3624\n",
      "Epoch 27/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8758 - loss: 0.3132 - val_accuracy: 0.8458 - val_loss: 0.3690\n",
      "Epoch 28/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8728 - loss: 0.3166 - val_accuracy: 0.8476 - val_loss: 0.3685\n",
      "Epoch 29/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.3178 - val_accuracy: 0.8493 - val_loss: 0.3650\n",
      "Epoch 30/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8705 - loss: 0.3187 - val_accuracy: 0.8474 - val_loss: 0.3701\n",
      "Epoch 31/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8729 - loss: 0.3127 - val_accuracy: 0.8491 - val_loss: 0.3669\n",
      "Epoch 32/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8747 - loss: 0.3074 - val_accuracy: 0.8459 - val_loss: 0.3698\n",
      "Epoch 33/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8713 - loss: 0.3089 - val_accuracy: 0.8474 - val_loss: 0.3688\n",
      "Epoch 34/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8758 - loss: 0.3051 - val_accuracy: 0.8414 - val_loss: 0.3741\n",
      "Epoch 35/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8738 - loss: 0.3093 - val_accuracy: 0.8426 - val_loss: 0.3703\n",
      "Epoch 36/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8751 - loss: 0.3056 - val_accuracy: 0.8444 - val_loss: 0.3744\n",
      "Epoch 37/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8786 - loss: 0.3044 - val_accuracy: 0.8459 - val_loss: 0.3699\n",
      "Epoch 38/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8752 - loss: 0.3019 - val_accuracy: 0.8471 - val_loss: 0.3734\n",
      "Epoch 39/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8760 - loss: 0.3043 - val_accuracy: 0.8461 - val_loss: 0.3750\n",
      "Epoch 40/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8764 - loss: 0.3003 - val_accuracy: 0.8450 - val_loss: 0.3740\n",
      "Epoch 41/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8745 - loss: 0.3061 - val_accuracy: 0.8450 - val_loss: 0.3733\n",
      "Epoch 42/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8758 - loss: 0.3003 - val_accuracy: 0.8428 - val_loss: 0.3781\n",
      "Epoch 43/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8793 - loss: 0.2977 - val_accuracy: 0.8424 - val_loss: 0.3766\n",
      "Epoch 44/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8781 - loss: 0.3021 - val_accuracy: 0.8422 - val_loss: 0.3780\n",
      "Epoch 45/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8808 - loss: 0.2901 - val_accuracy: 0.8405 - val_loss: 0.3765\n",
      "Epoch 46/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8804 - loss: 0.2948 - val_accuracy: 0.8433 - val_loss: 0.3809\n",
      "Epoch 47/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.2979 - val_accuracy: 0.8454 - val_loss: 0.3866\n",
      "Epoch 48/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8825 - loss: 0.2888 - val_accuracy: 0.8448 - val_loss: 0.3793\n",
      "Epoch 49/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.2935 - val_accuracy: 0.8422 - val_loss: 0.3837\n",
      "Epoch 50/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8769 - loss: 0.3004 - val_accuracy: 0.8411 - val_loss: 0.3848\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Performance for Neural Network h1n1_vaccine Model:\n",
      "Accuracy: 0.8410707600149757\n",
      "Confusion Matrix:\n",
      " [[3957  255]\n",
      " [ 594  536]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.94      0.90      4212\n",
      "         1.0       0.68      0.47      0.56      1130\n",
      "\n",
      "    accuracy                           0.84      5342\n",
      "   macro avg       0.77      0.71      0.73      5342\n",
      "weighted avg       0.83      0.84      0.83      5342\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loris\\Documents\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6573 - loss: 0.6167 - val_accuracy: 0.7634 - val_loss: 0.5021\n",
      "Epoch 2/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7489 - loss: 0.5245 - val_accuracy: 0.7671 - val_loss: 0.4979\n",
      "Epoch 3/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7581 - loss: 0.5100 - val_accuracy: 0.7707 - val_loss: 0.4914\n",
      "Epoch 4/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7653 - loss: 0.4957 - val_accuracy: 0.7701 - val_loss: 0.4923\n",
      "Epoch 5/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7685 - loss: 0.4946 - val_accuracy: 0.7731 - val_loss: 0.4891\n",
      "Epoch 6/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7642 - loss: 0.4972 - val_accuracy: 0.7739 - val_loss: 0.4889\n",
      "Epoch 7/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7676 - loss: 0.4905 - val_accuracy: 0.7716 - val_loss: 0.4898\n",
      "Epoch 8/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7703 - loss: 0.4912 - val_accuracy: 0.7742 - val_loss: 0.4889\n",
      "Epoch 9/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7716 - loss: 0.4836 - val_accuracy: 0.7733 - val_loss: 0.4903\n",
      "Epoch 10/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7731 - loss: 0.4841 - val_accuracy: 0.7756 - val_loss: 0.4862\n",
      "Epoch 11/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7732 - loss: 0.4815 - val_accuracy: 0.7769 - val_loss: 0.4858\n",
      "Epoch 12/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7777 - loss: 0.4742 - val_accuracy: 0.7709 - val_loss: 0.4895\n",
      "Epoch 13/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7829 - loss: 0.4719 - val_accuracy: 0.7765 - val_loss: 0.4868\n",
      "Epoch 14/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7865 - loss: 0.4649 - val_accuracy: 0.7722 - val_loss: 0.4874\n",
      "Epoch 15/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7821 - loss: 0.4696 - val_accuracy: 0.7759 - val_loss: 0.4870\n",
      "Epoch 16/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7838 - loss: 0.4646 - val_accuracy: 0.7744 - val_loss: 0.4864\n",
      "Epoch 17/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.4540 - val_accuracy: 0.7733 - val_loss: 0.4874\n",
      "Epoch 18/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7934 - loss: 0.4524 - val_accuracy: 0.7720 - val_loss: 0.4867\n",
      "Epoch 19/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7878 - loss: 0.4557 - val_accuracy: 0.7737 - val_loss: 0.4905\n",
      "Epoch 20/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7881 - loss: 0.4604 - val_accuracy: 0.7733 - val_loss: 0.4895\n",
      "Epoch 21/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7962 - loss: 0.4527 - val_accuracy: 0.7744 - val_loss: 0.4897\n",
      "Epoch 22/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7899 - loss: 0.4534 - val_accuracy: 0.7763 - val_loss: 0.4905\n",
      "Epoch 23/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7976 - loss: 0.4413 - val_accuracy: 0.7739 - val_loss: 0.4935\n",
      "Epoch 24/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7953 - loss: 0.4439 - val_accuracy: 0.7746 - val_loss: 0.4927\n",
      "Epoch 25/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7892 - loss: 0.4572 - val_accuracy: 0.7750 - val_loss: 0.4894\n",
      "Epoch 26/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7911 - loss: 0.4504 - val_accuracy: 0.7724 - val_loss: 0.4928\n",
      "Epoch 27/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7984 - loss: 0.4381 - val_accuracy: 0.7701 - val_loss: 0.4920\n",
      "Epoch 28/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7990 - loss: 0.4435 - val_accuracy: 0.7694 - val_loss: 0.4921\n",
      "Epoch 29/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7990 - loss: 0.4374 - val_accuracy: 0.7729 - val_loss: 0.4931\n",
      "Epoch 30/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7987 - loss: 0.4387 - val_accuracy: 0.7733 - val_loss: 0.4924\n",
      "Epoch 31/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7979 - loss: 0.4394 - val_accuracy: 0.7709 - val_loss: 0.4896\n",
      "Epoch 32/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7984 - loss: 0.4369 - val_accuracy: 0.7737 - val_loss: 0.4929\n",
      "Epoch 33/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8030 - loss: 0.4338 - val_accuracy: 0.7705 - val_loss: 0.4924\n",
      "Epoch 34/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7972 - loss: 0.4394 - val_accuracy: 0.7658 - val_loss: 0.5037\n",
      "Epoch 35/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7947 - loss: 0.4413 - val_accuracy: 0.7714 - val_loss: 0.4977\n",
      "Epoch 36/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8060 - loss: 0.4257 - val_accuracy: 0.7677 - val_loss: 0.5009\n",
      "Epoch 37/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7992 - loss: 0.4340 - val_accuracy: 0.7709 - val_loss: 0.4986\n",
      "Epoch 38/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8065 - loss: 0.4251 - val_accuracy: 0.7718 - val_loss: 0.4966\n",
      "Epoch 39/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8044 - loss: 0.4278 - val_accuracy: 0.7705 - val_loss: 0.5022\n",
      "Epoch 40/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: 0.4314 - val_accuracy: 0.7727 - val_loss: 0.5032\n",
      "Epoch 41/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8022 - loss: 0.4252 - val_accuracy: 0.7711 - val_loss: 0.4997\n",
      "Epoch 42/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8000 - loss: 0.4329 - val_accuracy: 0.7660 - val_loss: 0.5058\n",
      "Epoch 43/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.4184 - val_accuracy: 0.7692 - val_loss: 0.5041\n",
      "Epoch 44/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8016 - loss: 0.4283 - val_accuracy: 0.7726 - val_loss: 0.5017\n",
      "Epoch 45/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8038 - loss: 0.4270 - val_accuracy: 0.7744 - val_loss: 0.4989\n",
      "Epoch 46/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8065 - loss: 0.4211 - val_accuracy: 0.7699 - val_loss: 0.5046\n",
      "Epoch 47/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8116 - loss: 0.4195 - val_accuracy: 0.7671 - val_loss: 0.5010\n",
      "Epoch 48/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8075 - loss: 0.4153 - val_accuracy: 0.7656 - val_loss: 0.5099\n",
      "Epoch 49/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8106 - loss: 0.4152 - val_accuracy: 0.7697 - val_loss: 0.5065\n",
      "Epoch 50/50\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8052 - loss: 0.4232 - val_accuracy: 0.7701 - val_loss: 0.5037\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Performance for Neural Network seasonal_vaccine Model:\n",
      "Accuracy: 0.7701235492324972\n",
      "Confusion Matrix:\n",
      " [[2351  540]\n",
      " [ 688 1763]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.81      0.79      2891\n",
      "         1.0       0.77      0.72      0.74      2451\n",
      "\n",
      "    accuracy                           0.77      5342\n",
      "   macro avg       0.77      0.77      0.77      5342\n",
      "weighted avg       0.77      0.77      0.77      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Charger et préparer les données\n",
    "X = df.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])\n",
    "y_h1n1 = df['h1n1_vaccine']\n",
    "y_seasonal = df['seasonal_vaccine']\n",
    "\n",
    "\n",
    "# Séparer les données en ensemble d'entraînement et de validation\n",
    "X_train_h1n1, X_val_h1n1, y_train_h1n1, y_val_h1n1 = train_test_split(X, y_h1n1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construire le modèle de réseau de neurones\n",
    "model = Sequential([\n",
    "    Dense(128, input_dim=X_train_h1n1.shape[1], activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(X_train_h1n1, y_train_h1n1, epochs=50, batch_size=32, validation_data=(X_val_h1n1, y_val_h1n1), verbose=1)\n",
    "\n",
    "# Évaluer le modèle sur l'ensemble de validation\n",
    "y_pred_h1n1 = model.predict(X_val_h1n1)\n",
    "y_pred_h1n1_binary = (y_pred_h1n1 > 0.5).astype(int)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Performance for Neural Network h1n1_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_h1n1, y_pred_h1n1_binary))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_h1n1_binary))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_h1n1_binary))\n",
    "\n",
    "# Répéter pour seasonal_vaccine\n",
    "X_train_seasonal, X_val_seasonal, y_train_seasonal, y_val_seasonal = train_test_split(X, y_seasonal, test_size=0.2, random_state=42)\n",
    "\n",
    "model_seasonal = Sequential([\n",
    "    Dense(128, input_dim=X_train_seasonal.shape[1], activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_seasonal.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_seasonal = model_seasonal.fit(X_train_seasonal, y_train_seasonal, epochs=50, batch_size=32, validation_data=(X_val_seasonal, y_val_seasonal), verbose=1)\n",
    "\n",
    "y_pred_seasonal = model_seasonal.predict(X_val_seasonal)\n",
    "y_pred_seasonal_binary = (y_pred_seasonal > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nPerformance for Neural Network seasonal_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_seasonal, y_pred_seasonal_binary))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_seasonal, y_pred_seasonal_binary))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_seasonal, y_pred_seasonal_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17988ee7-daf5-4964-95d7-7d5d3b3e7ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\loris\\\\Desktop\\\\Flu_Prediction_Project\\\\seasonal_vaccine_neuronalmodel.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spécifier le chemin du dossier\n",
    "folder_path = r\"C:\\Users\\loris\\Desktop\\Flu_Prediction_Project\"\n",
    "\n",
    "# Exporter le modèle pour h1n1_vaccine\n",
    "joblib.dump(model, f\"{folder_path}\\\\h1n1_vaccine_neuronalmodel.pkl\")\n",
    "\n",
    "# Exporter le modèle pour seasonal_vaccine\n",
    "joblib.dump(model_seasonal, f\"{folder_path}\\\\seasonal_vaccine_neuronalmodel.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f4ea84-6c59-4656-827f-f63167abed60",
   "metadata": {},
   "source": [
    "# Neuronal network with L2 & Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53a02ac6-e8c1-4fa7-b9a3-9290d7e9ab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loris\\Documents\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7847 - loss: 1.3369 - val_accuracy: 0.8424 - val_loss: 0.4528\n",
      "Epoch 2/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.4480 - val_accuracy: 0.8443 - val_loss: 0.4186\n",
      "Epoch 3/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8417 - loss: 0.4287 - val_accuracy: 0.8428 - val_loss: 0.4263\n",
      "Epoch 4/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.4206 - val_accuracy: 0.8480 - val_loss: 0.4092\n",
      "Epoch 5/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4225 - val_accuracy: 0.8407 - val_loss: 0.4117\n",
      "Epoch 6/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8468 - loss: 0.4134 - val_accuracy: 0.8330 - val_loss: 0.4323\n",
      "Epoch 7/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.4063 - val_accuracy: 0.8437 - val_loss: 0.4050\n",
      "Epoch 8/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8447 - loss: 0.4169 - val_accuracy: 0.8480 - val_loss: 0.4033\n",
      "Epoch 9/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4156 - val_accuracy: 0.8486 - val_loss: 0.4001\n",
      "Epoch 10/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8461 - loss: 0.4124 - val_accuracy: 0.8446 - val_loss: 0.4098\n",
      "Epoch 11/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8461 - loss: 0.4109 - val_accuracy: 0.8493 - val_loss: 0.4028\n",
      "Epoch 12/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.4150 - val_accuracy: 0.8506 - val_loss: 0.4038\n",
      "Epoch 13/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8396 - loss: 0.4205 - val_accuracy: 0.8392 - val_loss: 0.4110\n",
      "Epoch 14/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.4132 - val_accuracy: 0.8463 - val_loss: 0.4037\n",
      "Epoch 15/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8478 - loss: 0.4052 - val_accuracy: 0.8495 - val_loss: 0.3985\n",
      "Epoch 16/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8445 - loss: 0.4118 - val_accuracy: 0.8531 - val_loss: 0.3940\n",
      "Epoch 17/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8453 - loss: 0.4091 - val_accuracy: 0.8465 - val_loss: 0.4020\n",
      "Epoch 18/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8498 - loss: 0.4021 - val_accuracy: 0.8472 - val_loss: 0.4042\n",
      "Epoch 19/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8433 - loss: 0.4064 - val_accuracy: 0.8480 - val_loss: 0.4000\n",
      "Epoch 20/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8458 - loss: 0.4100 - val_accuracy: 0.8501 - val_loss: 0.3952\n",
      "Epoch 21/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.4062 - val_accuracy: 0.8465 - val_loss: 0.4064\n",
      "Epoch 22/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8421 - loss: 0.4136 - val_accuracy: 0.8448 - val_loss: 0.3975\n",
      "Epoch 23/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.4085 - val_accuracy: 0.8489 - val_loss: 0.3962\n",
      "Epoch 24/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8459 - loss: 0.4066 - val_accuracy: 0.8446 - val_loss: 0.4050\n",
      "Epoch 25/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8487 - loss: 0.4014 - val_accuracy: 0.8517 - val_loss: 0.3939\n",
      "Epoch 26/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.4081 - val_accuracy: 0.8474 - val_loss: 0.4013\n",
      "Epoch 27/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8393 - loss: 0.4161 - val_accuracy: 0.8465 - val_loss: 0.3966\n",
      "Epoch 28/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.4000 - val_accuracy: 0.8504 - val_loss: 0.3915\n",
      "Epoch 29/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8465 - loss: 0.4111 - val_accuracy: 0.8471 - val_loss: 0.4008\n",
      "Epoch 30/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.4102 - val_accuracy: 0.8495 - val_loss: 0.3978\n",
      "Epoch 31/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.4018 - val_accuracy: 0.8478 - val_loss: 0.4012\n",
      "Epoch 32/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8440 - loss: 0.4112 - val_accuracy: 0.8478 - val_loss: 0.3955\n",
      "Epoch 33/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8458 - loss: 0.4088 - val_accuracy: 0.8482 - val_loss: 0.4022\n",
      "Epoch 34/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8443 - loss: 0.4031 - val_accuracy: 0.8486 - val_loss: 0.4069\n",
      "Epoch 35/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8444 - loss: 0.4065 - val_accuracy: 0.8502 - val_loss: 0.3979\n",
      "Epoch 36/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8450 - loss: 0.4069 - val_accuracy: 0.8482 - val_loss: 0.3954\n",
      "Epoch 37/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8488 - loss: 0.4051 - val_accuracy: 0.8465 - val_loss: 0.4009\n",
      "Epoch 38/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8472 - loss: 0.4042 - val_accuracy: 0.8474 - val_loss: 0.4006\n",
      "Epoch 39/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8509 - loss: 0.4016 - val_accuracy: 0.8439 - val_loss: 0.4047\n",
      "Epoch 40/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8470 - loss: 0.4084 - val_accuracy: 0.8472 - val_loss: 0.4039\n",
      "Epoch 41/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.4095 - val_accuracy: 0.8476 - val_loss: 0.3961\n",
      "Epoch 42/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.4038 - val_accuracy: 0.8484 - val_loss: 0.3931\n",
      "Epoch 43/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.4097 - val_accuracy: 0.8487 - val_loss: 0.3927\n",
      "Epoch 44/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8509 - loss: 0.3954 - val_accuracy: 0.8486 - val_loss: 0.3909\n",
      "Epoch 45/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8473 - loss: 0.4055 - val_accuracy: 0.8529 - val_loss: 0.3908\n",
      "Epoch 46/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8468 - loss: 0.4065 - val_accuracy: 0.8480 - val_loss: 0.3954\n",
      "Epoch 47/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8444 - loss: 0.4063 - val_accuracy: 0.8422 - val_loss: 0.3960\n",
      "Epoch 48/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8471 - loss: 0.4059 - val_accuracy: 0.8487 - val_loss: 0.3971\n",
      "Epoch 49/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.4013 - val_accuracy: 0.8476 - val_loss: 0.4052\n",
      "Epoch 50/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8468 - loss: 0.3987 - val_accuracy: 0.8444 - val_loss: 0.3950\n",
      "Epoch 51/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8475 - loss: 0.4022 - val_accuracy: 0.8486 - val_loss: 0.3923\n",
      "Epoch 52/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.4069 - val_accuracy: 0.8398 - val_loss: 0.4127\n",
      "Epoch 53/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8465 - loss: 0.4040 - val_accuracy: 0.8463 - val_loss: 0.4000\n",
      "Epoch 54/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8494 - loss: 0.4004 - val_accuracy: 0.8433 - val_loss: 0.3979\n",
      "Epoch 55/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8475 - loss: 0.4034 - val_accuracy: 0.8472 - val_loss: 0.3954\n",
      "Epoch 56/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8428 - loss: 0.4077 - val_accuracy: 0.8525 - val_loss: 0.3943\n",
      "Epoch 57/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8508 - loss: 0.3981 - val_accuracy: 0.8448 - val_loss: 0.4009\n",
      "Epoch 58/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.3955 - val_accuracy: 0.8456 - val_loss: 0.3977\n",
      "Epoch 59/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8403 - loss: 0.4105 - val_accuracy: 0.8471 - val_loss: 0.3958\n",
      "Epoch 60/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.4115 - val_accuracy: 0.8474 - val_loss: 0.4101\n",
      "Epoch 61/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8491 - loss: 0.4023 - val_accuracy: 0.8501 - val_loss: 0.4026\n",
      "Epoch 62/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8486 - loss: 0.3995 - val_accuracy: 0.8501 - val_loss: 0.3957\n",
      "Epoch 63/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8499 - loss: 0.3953 - val_accuracy: 0.8437 - val_loss: 0.4088\n",
      "Epoch 64/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8449 - loss: 0.4095 - val_accuracy: 0.8519 - val_loss: 0.3920\n",
      "Epoch 65/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8491 - loss: 0.3983 - val_accuracy: 0.8474 - val_loss: 0.3913\n",
      "Epoch 66/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4073 - val_accuracy: 0.8469 - val_loss: 0.4016\n",
      "Epoch 67/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8450 - loss: 0.4014 - val_accuracy: 0.8495 - val_loss: 0.4032\n",
      "Epoch 68/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.4045 - val_accuracy: 0.8476 - val_loss: 0.3964\n",
      "Epoch 69/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8436 - loss: 0.4066 - val_accuracy: 0.8439 - val_loss: 0.3983\n",
      "Epoch 70/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8417 - loss: 0.4049 - val_accuracy: 0.8467 - val_loss: 0.3966\n",
      "Epoch 71/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8481 - loss: 0.4056 - val_accuracy: 0.8469 - val_loss: 0.3951\n",
      "Epoch 72/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8481 - loss: 0.4029 - val_accuracy: 0.8499 - val_loss: 0.3920\n",
      "Epoch 73/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8457 - loss: 0.4020 - val_accuracy: 0.8458 - val_loss: 0.3969\n",
      "Epoch 74/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8501 - loss: 0.4012 - val_accuracy: 0.8487 - val_loss: 0.3931\n",
      "Epoch 75/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8418 - loss: 0.4093 - val_accuracy: 0.8458 - val_loss: 0.3966\n",
      "Epoch 76/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8444 - loss: 0.4044 - val_accuracy: 0.8502 - val_loss: 0.3954\n",
      "Epoch 77/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.4012 - val_accuracy: 0.8467 - val_loss: 0.3964\n",
      "Epoch 78/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8472 - loss: 0.4027 - val_accuracy: 0.8495 - val_loss: 0.3904\n",
      "Epoch 79/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.4056 - val_accuracy: 0.8478 - val_loss: 0.4002\n",
      "Epoch 80/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8484 - loss: 0.4005 - val_accuracy: 0.8472 - val_loss: 0.3922\n",
      "Epoch 81/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8450 - loss: 0.4009 - val_accuracy: 0.8499 - val_loss: 0.3925\n",
      "Epoch 82/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.3998 - val_accuracy: 0.8489 - val_loss: 0.3971\n",
      "Epoch 83/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8457 - loss: 0.4052 - val_accuracy: 0.8489 - val_loss: 0.3932\n",
      "Epoch 84/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8531 - loss: 0.3943 - val_accuracy: 0.8461 - val_loss: 0.4062\n",
      "Epoch 85/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.4067 - val_accuracy: 0.8502 - val_loss: 0.3895\n",
      "Epoch 86/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8472 - loss: 0.3999 - val_accuracy: 0.8476 - val_loss: 0.3972\n",
      "Epoch 87/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8467 - loss: 0.4020 - val_accuracy: 0.8444 - val_loss: 0.3919\n",
      "Epoch 88/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8488 - loss: 0.4068 - val_accuracy: 0.8484 - val_loss: 0.3909\n",
      "Epoch 89/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8494 - loss: 0.4020 - val_accuracy: 0.8486 - val_loss: 0.3911\n",
      "Epoch 90/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8437 - loss: 0.4055 - val_accuracy: 0.8484 - val_loss: 0.3999\n",
      "Epoch 91/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8424 - loss: 0.4081 - val_accuracy: 0.8504 - val_loss: 0.3935\n",
      "Epoch 92/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8496 - loss: 0.3939 - val_accuracy: 0.8467 - val_loss: 0.3981\n",
      "Epoch 93/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.3980 - val_accuracy: 0.8474 - val_loss: 0.3915\n",
      "Epoch 94/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8501 - loss: 0.3986 - val_accuracy: 0.8474 - val_loss: 0.3950\n",
      "Epoch 95/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.3995 - val_accuracy: 0.8486 - val_loss: 0.3951\n",
      "Epoch 96/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.4016 - val_accuracy: 0.8484 - val_loss: 0.3925\n",
      "Epoch 97/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8497 - loss: 0.3995 - val_accuracy: 0.8456 - val_loss: 0.4062\n",
      "Epoch 98/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8437 - loss: 0.4050 - val_accuracy: 0.8431 - val_loss: 0.4081\n",
      "Epoch 99/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8459 - loss: 0.4017 - val_accuracy: 0.8497 - val_loss: 0.3927\n",
      "Epoch 100/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8471 - loss: 0.3985 - val_accuracy: 0.8501 - val_loss: 0.3924\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Performance for Neural Network with Regularization h1n1_vaccine Model:\n",
      "Accuracy: 0.8500561587420442\n",
      "Confusion Matrix:\n",
      " [[4040  172]\n",
      " [ 629  501]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.96      0.91      4212\n",
      "         1.0       0.74      0.44      0.56      1130\n",
      "\n",
      "    accuracy                           0.85      5342\n",
      "   macro avg       0.80      0.70      0.73      5342\n",
      "weighted avg       0.84      0.85      0.83      5342\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loris\\Documents\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6783 - loss: 1.4762 - val_accuracy: 0.7684 - val_loss: 0.5810\n",
      "Epoch 2/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7529 - loss: 0.5808 - val_accuracy: 0.7585 - val_loss: 0.5533\n",
      "Epoch 3/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7580 - loss: 0.5585 - val_accuracy: 0.7712 - val_loss: 0.5417\n",
      "Epoch 4/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7573 - loss: 0.5518 - val_accuracy: 0.7598 - val_loss: 0.5413\n",
      "Epoch 5/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7550 - loss: 0.5508 - val_accuracy: 0.7671 - val_loss: 0.5370\n",
      "Epoch 6/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7617 - loss: 0.5466 - val_accuracy: 0.7701 - val_loss: 0.5304\n",
      "Epoch 7/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7560 - loss: 0.5558 - val_accuracy: 0.7658 - val_loss: 0.5381\n",
      "Epoch 8/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7613 - loss: 0.5479 - val_accuracy: 0.7606 - val_loss: 0.5416\n",
      "Epoch 9/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7629 - loss: 0.5448 - val_accuracy: 0.7559 - val_loss: 0.5473\n",
      "Epoch 10/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7580 - loss: 0.5456 - val_accuracy: 0.7692 - val_loss: 0.5297\n",
      "Epoch 11/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7564 - loss: 0.5481 - val_accuracy: 0.7653 - val_loss: 0.5331\n",
      "Epoch 12/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7552 - loss: 0.5442 - val_accuracy: 0.7690 - val_loss: 0.5310\n",
      "Epoch 13/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7603 - loss: 0.5486 - val_accuracy: 0.7716 - val_loss: 0.5285\n",
      "Epoch 14/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7642 - loss: 0.5423 - val_accuracy: 0.7540 - val_loss: 0.5494\n",
      "Epoch 15/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7547 - loss: 0.5488 - val_accuracy: 0.7653 - val_loss: 0.5316\n",
      "Epoch 16/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7565 - loss: 0.5481 - val_accuracy: 0.7737 - val_loss: 0.5266\n",
      "Epoch 17/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7595 - loss: 0.5447 - val_accuracy: 0.7638 - val_loss: 0.5331\n",
      "Epoch 18/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7563 - loss: 0.5496 - val_accuracy: 0.7705 - val_loss: 0.5287\n",
      "Epoch 19/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7665 - loss: 0.5426 - val_accuracy: 0.7688 - val_loss: 0.5308\n",
      "Epoch 20/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7648 - loss: 0.5386 - val_accuracy: 0.7660 - val_loss: 0.5314\n",
      "Epoch 21/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7627 - loss: 0.5418 - val_accuracy: 0.7701 - val_loss: 0.5298\n",
      "Epoch 22/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7570 - loss: 0.5425 - val_accuracy: 0.7615 - val_loss: 0.5322\n",
      "Epoch 23/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7626 - loss: 0.5464 - val_accuracy: 0.7653 - val_loss: 0.5318\n",
      "Epoch 24/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7619 - loss: 0.5395 - val_accuracy: 0.7690 - val_loss: 0.5245\n",
      "Epoch 25/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7566 - loss: 0.5456 - val_accuracy: 0.7699 - val_loss: 0.5290\n",
      "Epoch 26/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7638 - loss: 0.5393 - val_accuracy: 0.7750 - val_loss: 0.5238\n",
      "Epoch 27/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7566 - loss: 0.5508 - val_accuracy: 0.7681 - val_loss: 0.5261\n",
      "Epoch 28/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7599 - loss: 0.5464 - val_accuracy: 0.7714 - val_loss: 0.5247\n",
      "Epoch 29/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7618 - loss: 0.5422 - val_accuracy: 0.7729 - val_loss: 0.5266\n",
      "Epoch 30/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7639 - loss: 0.5376 - val_accuracy: 0.7697 - val_loss: 0.5280\n",
      "Epoch 31/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7651 - loss: 0.5356 - val_accuracy: 0.7720 - val_loss: 0.5285\n",
      "Epoch 32/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7645 - loss: 0.5373 - val_accuracy: 0.7688 - val_loss: 0.5291\n",
      "Epoch 33/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7697 - loss: 0.5291 - val_accuracy: 0.7696 - val_loss: 0.5287\n",
      "Epoch 34/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7591 - loss: 0.5426 - val_accuracy: 0.7726 - val_loss: 0.5260\n",
      "Epoch 35/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7547 - loss: 0.5443 - val_accuracy: 0.7681 - val_loss: 0.5247\n",
      "Epoch 36/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7648 - loss: 0.5373 - val_accuracy: 0.7690 - val_loss: 0.5250\n",
      "Epoch 37/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7578 - loss: 0.5419 - val_accuracy: 0.7668 - val_loss: 0.5294\n",
      "Epoch 38/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7646 - loss: 0.5361 - val_accuracy: 0.7720 - val_loss: 0.5259\n",
      "Epoch 39/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7607 - loss: 0.5387 - val_accuracy: 0.7692 - val_loss: 0.5248\n",
      "Epoch 40/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7647 - loss: 0.5394 - val_accuracy: 0.7643 - val_loss: 0.5317\n",
      "Epoch 41/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7643 - loss: 0.5380 - val_accuracy: 0.7608 - val_loss: 0.5330\n",
      "Epoch 42/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7606 - loss: 0.5371 - val_accuracy: 0.7654 - val_loss: 0.5262\n",
      "Epoch 43/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7647 - loss: 0.5361 - val_accuracy: 0.7697 - val_loss: 0.5244\n",
      "Epoch 44/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7595 - loss: 0.5391 - val_accuracy: 0.7718 - val_loss: 0.5255\n",
      "Epoch 45/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7590 - loss: 0.5399 - val_accuracy: 0.7769 - val_loss: 0.5208\n",
      "Epoch 46/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7615 - loss: 0.5366 - val_accuracy: 0.7675 - val_loss: 0.5269\n",
      "Epoch 47/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7595 - loss: 0.5362 - val_accuracy: 0.7668 - val_loss: 0.5302\n",
      "Epoch 48/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7668 - loss: 0.5393 - val_accuracy: 0.7684 - val_loss: 0.5239\n",
      "Epoch 49/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7637 - loss: 0.5402 - val_accuracy: 0.7718 - val_loss: 0.5265\n",
      "Epoch 50/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7638 - loss: 0.5339 - val_accuracy: 0.7712 - val_loss: 0.5298\n",
      "Epoch 51/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7604 - loss: 0.5359 - val_accuracy: 0.7684 - val_loss: 0.5261\n",
      "Epoch 52/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7663 - loss: 0.5349 - val_accuracy: 0.7709 - val_loss: 0.5260\n",
      "Epoch 53/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7661 - loss: 0.5346 - val_accuracy: 0.7754 - val_loss: 0.5214\n",
      "Epoch 54/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7672 - loss: 0.5366 - val_accuracy: 0.7658 - val_loss: 0.5259\n",
      "Epoch 55/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7621 - loss: 0.5411 - val_accuracy: 0.7675 - val_loss: 0.5225\n",
      "Epoch 56/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7701 - loss: 0.5345 - val_accuracy: 0.7712 - val_loss: 0.5217\n",
      "Epoch 57/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7651 - loss: 0.5376 - val_accuracy: 0.7697 - val_loss: 0.5272\n",
      "Epoch 58/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7613 - loss: 0.5385 - val_accuracy: 0.7712 - val_loss: 0.5256\n",
      "Epoch 59/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7617 - loss: 0.5372 - val_accuracy: 0.7683 - val_loss: 0.5267\n",
      "Epoch 60/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7513 - loss: 0.5456 - val_accuracy: 0.7739 - val_loss: 0.5220\n",
      "Epoch 61/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7561 - loss: 0.5463 - val_accuracy: 0.7653 - val_loss: 0.5260\n",
      "Epoch 62/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7627 - loss: 0.5372 - val_accuracy: 0.7763 - val_loss: 0.5220\n",
      "Epoch 63/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7639 - loss: 0.5350 - val_accuracy: 0.7630 - val_loss: 0.5277\n",
      "Epoch 64/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7646 - loss: 0.5382 - val_accuracy: 0.7712 - val_loss: 0.5220\n",
      "Epoch 65/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7613 - loss: 0.5371 - val_accuracy: 0.7681 - val_loss: 0.5212\n",
      "Epoch 66/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7597 - loss: 0.5376 - val_accuracy: 0.7690 - val_loss: 0.5261\n",
      "Epoch 67/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7613 - loss: 0.5377 - val_accuracy: 0.7697 - val_loss: 0.5263\n",
      "Epoch 68/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7630 - loss: 0.5369 - val_accuracy: 0.7690 - val_loss: 0.5238\n",
      "Epoch 69/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7599 - loss: 0.5358 - val_accuracy: 0.7731 - val_loss: 0.5219\n",
      "Epoch 70/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7597 - loss: 0.5394 - val_accuracy: 0.7711 - val_loss: 0.5242\n",
      "Epoch 71/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7567 - loss: 0.5423 - val_accuracy: 0.7649 - val_loss: 0.5306\n",
      "Epoch 72/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7671 - loss: 0.5332 - val_accuracy: 0.7705 - val_loss: 0.5244\n",
      "Epoch 73/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7611 - loss: 0.5429 - val_accuracy: 0.7750 - val_loss: 0.5217\n",
      "Epoch 74/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7603 - loss: 0.5357 - val_accuracy: 0.7619 - val_loss: 0.5301\n",
      "Epoch 75/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7660 - loss: 0.5326 - val_accuracy: 0.7696 - val_loss: 0.5276\n",
      "Epoch 76/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7583 - loss: 0.5399 - val_accuracy: 0.7720 - val_loss: 0.5245\n",
      "Epoch 77/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7602 - loss: 0.5360 - val_accuracy: 0.7668 - val_loss: 0.5254\n",
      "Epoch 78/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7627 - loss: 0.5308 - val_accuracy: 0.7662 - val_loss: 0.5264\n",
      "Epoch 79/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7613 - loss: 0.5319 - val_accuracy: 0.7649 - val_loss: 0.5277\n",
      "Epoch 80/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7591 - loss: 0.5413 - val_accuracy: 0.7701 - val_loss: 0.5228\n",
      "Epoch 81/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7675 - loss: 0.5331 - val_accuracy: 0.7686 - val_loss: 0.5259\n",
      "Epoch 82/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7565 - loss: 0.5425 - val_accuracy: 0.7701 - val_loss: 0.5237\n",
      "Epoch 83/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7658 - loss: 0.5340 - val_accuracy: 0.7733 - val_loss: 0.5201\n",
      "Epoch 84/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7596 - loss: 0.5376 - val_accuracy: 0.7711 - val_loss: 0.5253\n",
      "Epoch 85/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7598 - loss: 0.5424 - val_accuracy: 0.7671 - val_loss: 0.5280\n",
      "Epoch 86/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7608 - loss: 0.5369 - val_accuracy: 0.7712 - val_loss: 0.5205\n",
      "Epoch 87/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7633 - loss: 0.5349 - val_accuracy: 0.7726 - val_loss: 0.5226\n",
      "Epoch 88/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7634 - loss: 0.5290 - val_accuracy: 0.7673 - val_loss: 0.5244\n",
      "Epoch 89/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7633 - loss: 0.5349 - val_accuracy: 0.7726 - val_loss: 0.5175\n",
      "Epoch 90/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7668 - loss: 0.5296 - val_accuracy: 0.7658 - val_loss: 0.5254\n",
      "Epoch 91/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7616 - loss: 0.5311 - val_accuracy: 0.7731 - val_loss: 0.5242\n",
      "Epoch 92/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7659 - loss: 0.5294 - val_accuracy: 0.7701 - val_loss: 0.5221\n",
      "Epoch 93/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7683 - loss: 0.5278 - val_accuracy: 0.7690 - val_loss: 0.5230\n",
      "Epoch 94/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7622 - loss: 0.5388 - val_accuracy: 0.7690 - val_loss: 0.5237\n",
      "Epoch 95/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.5374 - val_accuracy: 0.7666 - val_loss: 0.5269\n",
      "Epoch 96/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7628 - loss: 0.5343 - val_accuracy: 0.7739 - val_loss: 0.5208\n",
      "Epoch 97/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7640 - loss: 0.5340 - val_accuracy: 0.7731 - val_loss: 0.5220\n",
      "Epoch 98/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7614 - loss: 0.5362 - val_accuracy: 0.7673 - val_loss: 0.5278\n",
      "Epoch 99/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7577 - loss: 0.5405 - val_accuracy: 0.7709 - val_loss: 0.5223\n",
      "Epoch 100/100\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7593 - loss: 0.5411 - val_accuracy: 0.7707 - val_loss: 0.5289\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Performance for Neural Network with Regularization seasonal_vaccine Model:\n",
      "Accuracy: 0.770685136652939\n",
      "Confusion Matrix:\n",
      " [[2425  466]\n",
      " [ 759 1692]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.84      0.80      2891\n",
      "         1.0       0.78      0.69      0.73      2451\n",
      "\n",
      "    accuracy                           0.77      5342\n",
      "   macro avg       0.77      0.76      0.77      5342\n",
      "weighted avg       0.77      0.77      0.77      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Charger et préparer les données\n",
    "X = df.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])\n",
    "y_h1n1 = df['h1n1_vaccine']\n",
    "y_seasonal = df['seasonal_vaccine']\n",
    "\n",
    "# Normaliser les données\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Séparer les données en ensemble d'entraînement et de validation\n",
    "X_train_h1n1, X_val_h1n1, y_train_h1n1, y_val_h1n1 = train_test_split(X, y_h1n1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construire le modèle de réseau de neurones avec régularisation L2 et Dropout\n",
    "model = Sequential([\n",
    "    Dense(128, input_dim=X_train_h1n1.shape[1], activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.4),  # Dropout de 40%\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.4),  # Dropout de 40%\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(X_train_h1n1, y_train_h1n1, epochs=100, batch_size=32, validation_data=(X_val_h1n1, y_val_h1n1), verbose=1)\n",
    "\n",
    "# Évaluer le modèle sur l'ensemble de validation\n",
    "y_pred_h1n1 = model.predict(X_val_h1n1)\n",
    "y_pred_h1n1_binary = (y_pred_h1n1 > 0.5).astype(int)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Performance for Neural Network with Regularization h1n1_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_h1n1, y_pred_h1n1_binary))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_h1n1_binary))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_h1n1_binary))\n",
    "\n",
    "# Répéter pour seasonal_vaccine\n",
    "X_train_seasonal, X_val_seasonal, y_train_seasonal, y_val_seasonal = train_test_split(X, y_seasonal, test_size=0.2, random_state=42)\n",
    "\n",
    "model_seasonal = Sequential([\n",
    "    Dense(128, input_dim=X_train_seasonal.shape[1], activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.4),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_seasonal.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_seasonal = model_seasonal.fit(X_train_seasonal, y_train_seasonal, epochs=100, batch_size=32, validation_data=(X_val_seasonal, y_val_seasonal), verbose=1)\n",
    "\n",
    "y_pred_seasonal = model_seasonal.predict(X_val_seasonal)\n",
    "y_pred_seasonal_binary = (y_pred_seasonal > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nPerformance for Neural Network with Regularization seasonal_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_seasonal, y_pred_seasonal_binary))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_seasonal, y_pred_seasonal_binary))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_seasonal, y_pred_seasonal_binary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cb78fc-726c-4c46-b05b-d85a9d4896dd",
   "metadata": {},
   "source": [
    "# Neuronal network + ensemble + voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6d1f3c5-843e-42b1-971b-e6ed05cfb93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4544, number of negative: 16821\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 198\n",
      "[LightGBM] [Info] Number of data points in the train set: 21365, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.212684 -> initscore=-1.308820\n",
      "[LightGBM] [Info] Start training from score -1.308820\n",
      "[LightGBM] [Info] Number of positive: 3636, number of negative: 13456\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 198\n",
      "[LightGBM] [Info] Number of data points in the train set: 17092, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.212731 -> initscore=-1.308541\n",
      "[LightGBM] [Info] Start training from score -1.308541\n",
      "[LightGBM] [Info] Number of positive: 3635, number of negative: 13457\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 198\n",
      "[LightGBM] [Info] Number of data points in the train set: 17092, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.212673 -> initscore=-1.308890\n",
      "[LightGBM] [Info] Start training from score -1.308890\n",
      "[LightGBM] [Info] Number of positive: 3635, number of negative: 13457\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 198\n",
      "[LightGBM] [Info] Number of data points in the train set: 17092, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.212673 -> initscore=-1.308890\n",
      "[LightGBM] [Info] Start training from score -1.308890\n",
      "[LightGBM] [Info] Number of positive: 3635, number of negative: 13457\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 198\n",
      "[LightGBM] [Info] Number of data points in the train set: 17092, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.212673 -> initscore=-1.308890\n",
      "[LightGBM] [Info] Start training from score -1.308890\n",
      "[LightGBM] [Info] Number of positive: 3635, number of negative: 13457\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 198\n",
      "[LightGBM] [Info] Number of data points in the train set: 17092, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.212673 -> initscore=-1.308890\n",
      "[LightGBM] [Info] Start training from score -1.308890\n",
      "Performance for Voting Classifier h1n1_vaccine Model:\n",
      "Accuracy: 0.8536128790715088\n",
      "Confusion Matrix:\n",
      " [[3983  229]\n",
      " [ 553  577]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.95      0.91      4212\n",
      "         1.0       0.72      0.51      0.60      1130\n",
      "\n",
      "    accuracy                           0.85      5342\n",
      "   macro avg       0.80      0.73      0.75      5342\n",
      "weighted avg       0.84      0.85      0.84      5342\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 9984, number of negative: 11381\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 198\n",
      "[LightGBM] [Info] Number of data points in the train set: 21365, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.467306 -> initscore=-0.130961\n",
      "[LightGBM] [Info] Start training from score -0.130961\n",
      "[LightGBM] [Info] Number of positive: 7988, number of negative: 9104\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 198\n",
      "[LightGBM] [Info] Number of data points in the train set: 17092, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.467353 -> initscore=-0.130773\n",
      "[LightGBM] [Info] Start training from score -0.130773\n",
      "[LightGBM] [Info] Number of positive: 7987, number of negative: 9105\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 198\n",
      "[LightGBM] [Info] Number of data points in the train set: 17092, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.467295 -> initscore=-0.131008\n",
      "[LightGBM] [Info] Start training from score -0.131008\n",
      "[LightGBM] [Info] Number of positive: 7987, number of negative: 9105\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 198\n",
      "[LightGBM] [Info] Number of data points in the train set: 17092, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.467295 -> initscore=-0.131008\n",
      "[LightGBM] [Info] Start training from score -0.131008\n",
      "[LightGBM] [Info] Number of positive: 7987, number of negative: 9105\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 198\n",
      "[LightGBM] [Info] Number of data points in the train set: 17092, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.467295 -> initscore=-0.131008\n",
      "[LightGBM] [Info] Start training from score -0.131008\n",
      "[LightGBM] [Info] Number of positive: 7987, number of negative: 9105\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 198\n",
      "[LightGBM] [Info] Number of data points in the train set: 17092, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.467295 -> initscore=-0.131008\n",
      "[LightGBM] [Info] Start training from score -0.131008\n",
      "\n",
      "Performance for Voting Classifier seasonal_vaccine Model:\n",
      "Accuracy: 0.7920254586297267\n",
      "Confusion Matrix:\n",
      " [[2360  531]\n",
      " [ 580 1871]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.82      0.81      2891\n",
      "         1.0       0.78      0.76      0.77      2451\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.79      0.79      0.79      5342\n",
      "weighted avg       0.79      0.79      0.79      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Charger les modèles pré-entraînés\n",
    "folder_path = r\"C:\\Users\\loris\\Desktop\\Flu_Prediction_Project\"\n",
    "\n",
    "h1n1_vaccine_rfmodel = joblib.load(f\"{folder_path}\\\\h1n1_vaccine_rfmodel.pkl\")\n",
    "seasonal_vaccine_rfmodel = joblib.load(f\"{folder_path}\\\\seasonal_vaccine_rfmodel.pkl\")\n",
    "stacking_h1n1_vaccine_model = joblib.load(f\"{folder_path}\\\\stacking_h1n1_vaccine_model.pkl\")\n",
    "stacking_seasonal_vaccine_model = joblib.load(f\"{folder_path}\\\\stacking_seasonal_vaccine_model.pkl\")\n",
    "\n",
    "# Assurez-vous que X_train_h1n1, y_train_h1n1, X_val_h1n1, y_val_h1n1 soient déjà définis dans le notebook\n",
    "\n",
    "# Créer le Voting Classifier pour h1n1_vaccine\n",
    "voting_clf_h1n1 = VotingClassifier(estimators=[\n",
    "    ('rf', h1n1_vaccine_rfmodel),\n",
    "    ('stacking', stacking_h1n1_vaccine_model)\n",
    "], voting='soft')\n",
    "\n",
    "# Entraîner le Voting Classifier pour h1n1_vaccine\n",
    "voting_clf_h1n1.fit(X_train_h1n1, y_train_h1n1)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de validation\n",
    "y_pred_h1n1 = voting_clf_h1n1.predict(X_val_h1n1)\n",
    "\n",
    "# Évaluer les performances\n",
    "print(\"Performance for Voting Classifier h1n1_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_h1n1, y_pred_h1n1))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_h1n1))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_h1n1))\n",
    "\n",
    "# Répéter pour seasonal_vaccine\n",
    "voting_clf_seasonal = VotingClassifier(estimators=[\n",
    "    ('rf', seasonal_vaccine_rfmodel),\n",
    "    ('stacking', stacking_seasonal_vaccine_model)\n",
    "], voting='soft')\n",
    "\n",
    "voting_clf_seasonal.fit(X_train_seasonal, y_train_seasonal)\n",
    "\n",
    "y_pred_seasonal = voting_clf_seasonal.predict(X_val_seasonal)\n",
    "\n",
    "print(\"\\nPerformance for Voting Classifier seasonal_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_seasonal, y_pred_seasonal))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_seasonal, y_pred_seasonal))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_seasonal, y_pred_seasonal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e084650-9b0e-491b-9492-bdb388dfb850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle h1n1_vaccine_neurovoting a été enregistré sous le nom 'h1n1_vaccine_neurovoting.pkl'.\n",
      "Le modèle seasonal_vaccine_neurovoting a été enregistré sous le nom 'seasonal_vaccine_neurovoting.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Exporter le modèle Voting Classifier pour h1n1_vaccine\n",
    "joblib.dump(voting_clf_h1n1, f\"{folder_path}\\\\h1n1_vaccine_neurovoting.pkl\")\n",
    "print(\"Le modèle h1n1_vaccine_neurovoting a été enregistré sous le nom 'h1n1_vaccine_neurovoting.pkl'.\")\n",
    "\n",
    "# Exporter le modèle Voting Classifier pour seasonal_vaccine\n",
    "joblib.dump(voting_clf_seasonal, f\"{folder_path}\\\\seasonal_vaccine_neurovoting.pkl\")\n",
    "print(\"Le modèle seasonal_vaccine_neurovoting a été enregistré sous le nom 'seasonal_vaccine_neurovoting.pkl'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da1e11-dcdb-4219-8947-314f031e6bf7",
   "metadata": {},
   "source": [
    "# SMOTE + undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b884c6d4-b84d-41f4-a1be-ab0aa0a61fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Balanced Gradient Boosting h1n1_vaccine Model:\n",
      "Accuracy: 0.850430550355672\n",
      "Confusion Matrix:\n",
      " [[3947  265]\n",
      " [ 534  596]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.94      0.91      4212\n",
      "         1.0       0.69      0.53      0.60      1130\n",
      "\n",
      "    accuracy                           0.85      5342\n",
      "   macro avg       0.79      0.73      0.75      5342\n",
      "weighted avg       0.84      0.85      0.84      5342\n",
      "\n",
      "\n",
      "Performance for Balanced Gradient Boosting seasonal_vaccine Model:\n",
      "Accuracy: 0.7905278921752152\n",
      "Confusion Matrix:\n",
      " [[2346  545]\n",
      " [ 574 1877]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.81      0.81      2891\n",
      "         1.0       0.77      0.77      0.77      2451\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.79      0.79      0.79      5342\n",
      "weighted avg       0.79      0.79      0.79      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE  # Importation de SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Charger et préparer les données\n",
    "X = df.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])\n",
    "y_h1n1 = df['h1n1_vaccine']\n",
    "y_seasonal = df['seasonal_vaccine']\n",
    "\n",
    "# Séparer les données en ensemble d'entraînement et de validation\n",
    "X_train_h1n1, X_val_h1n1, y_train_h1n1, y_val_h1n1 = train_test_split(X, y_h1n1, test_size=0.2, random_state=42)\n",
    "X_train_seasonal, X_val_seasonal, y_train_seasonal, y_val_seasonal = train_test_split(X, y_seasonal, test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer un pipeline pour rééquilibrer les classes\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy='majority', random_state=42)\n",
    "\n",
    "# Pipeline pour h1n1_vaccine\n",
    "pipeline_h1n1 = ImbPipeline(steps=[('smote', smote), ('under', under), ('model', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42))])\n",
    "\n",
    "# Entraîner le modèle après rééquilibrage\n",
    "pipeline_h1n1.fit(X_train_h1n1, y_train_h1n1)\n",
    "\n",
    "# Faire des prédictions\n",
    "y_pred_h1n1 = pipeline_h1n1.predict(X_val_h1n1)\n",
    "\n",
    "# Évaluer les performances\n",
    "print(\"Performance for Balanced Gradient Boosting h1n1_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_h1n1, y_pred_h1n1))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_h1n1))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_h1n1))\n",
    "\n",
    "# Pipeline pour seasonal_vaccine\n",
    "pipeline_seasonal = ImbPipeline(steps=[('smote', smote), ('under', under), ('model', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42))])\n",
    "\n",
    "# Entraîner le modèle après rééquilibrage\n",
    "pipeline_seasonal.fit(X_train_seasonal, y_train_seasonal)\n",
    "\n",
    "# Faire des prédictions\n",
    "y_pred_seasonal = pipeline_seasonal.predict(X_val_seasonal)\n",
    "\n",
    "# Évaluer les performances\n",
    "print(\"\\nPerformance for Balanced Gradient Boosting seasonal_vaccine Model:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_seasonal, y_pred_seasonal))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_seasonal, y_pred_seasonal))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_seasonal, y_pred_seasonal))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c427aaf-1c67-4479-b590-ef34732dae3b",
   "metadata": {},
   "source": [
    "# Optimizing the recall for the minority class (5 steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0cc80c9c-d2de-4600-9fd4-97fb447785dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3340  872]\n",
      " [ 246  884]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.79      0.86      4212\n",
      "         1.0       0.50      0.78      0.61      1130\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.72      0.79      0.73      5342\n",
      "weighted avg       0.84      0.79      0.81      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Étape 1 : Ajustement du Seuil de Décision\n",
    "y_proba_h1n1 = model_h1n1_optimized.predict_proba(X_val_h1n1)[:, 1]\n",
    "threshold = 0.3\n",
    "y_pred_h1n1_adjusted = [1 if prob > threshold else 0 for prob in y_proba_h1n1]\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_h1n1_adjusted))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_h1n1_adjusted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ed4cf6b-4019-4067-b679-ea934dfc6dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loris\\Documents\\Anaconda\\Lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3772  440]\n",
      " [ 416  714]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.90      0.90      4212\n",
      "         1.0       0.62      0.63      0.63      1130\n",
      "\n",
      "    accuracy                           0.84      5342\n",
      "   macro avg       0.76      0.76      0.76      5342\n",
      "weighted avg       0.84      0.84      0.84      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Étape 2 : Pondération des Classes\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # Nécessaire pour activer le modèle\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# Modèle avec pondération des classes\n",
    "model_h1n1_weighted = HistGradientBoostingClassifier(random_state=42, class_weight={0: 1, 1: 2})\n",
    "model_h1n1_weighted.fit(X_train_h1n1, y_train_h1n1)\n",
    "\n",
    "# Prédictions et évaluation\n",
    "y_pred_h1n1_weighted = model_h1n1_weighted.predict(X_val_h1n1)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_h1n1_weighted))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_h1n1_weighted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf6358f2-3ed7-4bc4-b46f-d3f79d10dbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loris\\Documents\\Anaconda\\Lib\\site-packages\\imblearn\\ensemble\\_forest.py:546: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\loris\\Documents\\Anaconda\\Lib\\site-packages\\imblearn\\ensemble\\_forest.py:558: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3371  841]\n",
      " [ 266  864]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.80      0.86      4212\n",
      "         1.0       0.51      0.76      0.61      1130\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.72      0.78      0.73      5342\n",
      "weighted avg       0.84      0.79      0.81      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Étape 3 : Utilisation de Techniques d'Ensemble Spécialisées\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier  # Importation nécessaire\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Étape 3 : Utilisation de Techniques d'Ensemble Spécialisées\n",
    "brf = BalancedRandomForestClassifier(n_estimators=100, random_state=42)\n",
    "brf.fit(X_train_h1n1, y_train_h1n1)\n",
    "y_pred_brf_h1n1 = brf.predict(X_val_h1n1)\n",
    "\n",
    "# Évaluer les performances\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_brf_h1n1))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_brf_h1n1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2715efa0-c483-49f2-8872-aadef0a1ae08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3947  265]\n",
      " [ 534  596]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.94      0.91      4212\n",
      "         1.0       0.69      0.53      0.60      1130\n",
      "\n",
      "    accuracy                           0.85      5342\n",
      "   macro avg       0.79      0.73      0.75      5342\n",
      "weighted avg       0.84      0.85      0.84      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Étape 4 : Rééchantillonnage Avancé des Données\n",
    "pipeline_smote_h1n1 = ImbPipeline(steps=[('smote', SMOTE(sampling_strategy='minority', random_state=42)), ('under', RandomUnderSampler(sampling_strategy='majority', random_state=42)), ('model', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42))])\n",
    "pipeline_smote_h1n1.fit(X_train_h1n1, y_train_h1n1)\n",
    "y_pred_smote_h1n1 = pipeline_smote_h1n1.predict(X_val_h1n1)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_smote_h1n1))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_smote_h1n1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31ccf802-e159-48d8-aaa2-9386ae20e4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for h1n1_vaccine: {'class_weight': {0: 1, 1: 5}, 'learning_rate': 0.01, 'max_depth': 7, 'max_iter': 50}\n",
      "Confusion Matrix:\n",
      " [[2688 1524]\n",
      " [ 133  997]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.64      0.76      4212\n",
      "         1.0       0.40      0.88      0.55      1130\n",
      "\n",
      "    accuracy                           0.69      5342\n",
      "   macro avg       0.67      0.76      0.66      5342\n",
      "weighted avg       0.83      0.69      0.72      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Étape 5 : Optimisation des Hyperparamètres\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # Nécessaire pour activer le modèle\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Remplacer GradientBoostingClassifier par HistGradientBoostingClassifier\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_iter': [50, 100, 200],\n",
    "    'class_weight': [{0: 1, 1: w} for w in [1, 2, 5]]\n",
    "}\n",
    "\n",
    "grid_search_h1n1 = GridSearchCV(HistGradientBoostingClassifier(random_state=42), param_grid, scoring='recall', cv=5)\n",
    "grid_search_h1n1.fit(X_train_h1n1, y_train_h1n1)\n",
    "best_model_h1n1 = grid_search_h1n1.best_estimator_\n",
    "y_pred_best_h1n1 = best_model_h1n1.predict(X_val_h1n1)\n",
    "\n",
    "print(\"Best Hyperparameters for h1n1_vaccine:\", grid_search_h1n1.best_params_)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val_h1n1, y_pred_best_h1n1))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_h1n1, y_pred_best_h1n1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
